{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHsOUuB7HVCYTVPxYcT7/Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MÓDULO 7.  Introducción a Deep Learning  (8 horas)"],"metadata":{"id":"zqRoN9POHLig"}},{"cell_type":"markdown","source":["# Introducción al Deep Learning\n","\n","El Deep Learning (aprendizaje profundo) es un subconjunto de técnicas de Machine Learning (aprendizaje de máquina) que ha venido en crecimiento desde hace aproximadamente 10 años. A la vez, el aprendizaje de máquina es un subconjunto de la Artificial Intelligence (Inteligencia Artificial).\n","\n","![picture](https://drive.google.com/uc?id=1o2RV-EH-UTZp--iNAUqXu54BUOq0_TAl)\n","\n","**Fuente: AI & Machine Learning: The evolution, differences and connections - Kapil Tandon**\n"],"metadata":{"id":"C6FTXu7mParm"}},{"cell_type":"markdown","source":["# Artificila Intelligence (AI)\n","\n","La AI es una rama de investigación dentro de las ciencias computacionales (Computer Science). El objetivo principal de la AI es simular la capacidad de adquisicióón de información, análisis de datos y toma de decisiones de los humanos.\n","\n","![](https://drive.google.com/uc?id=1Fbfnpk4vNqDQ47EEmanc7qzDtOsHlMny)\n","\n","\n","**Inicios**\n","\n","La IA tuvo sus primeros pasos a finales de la década de 1950, comenzó como un simple reto de programar computadoras para que tuvieran la capacidad de resolver problemas que los humanos hacen con facilidad, pero que las computadoras no habían podido realizar hasta el momento.\n","\n","En 1950 **Allan Turing** consolidó el campo de la inteligencia artificial con su artículo *Computing Machinery and Intelligence*, en el que propuso una prueba concreta para determinar si una máquina era inteligente o no. A partir de su trabajo se hizo famosa la *Prueba de Turing* una prueba que evalua si un resultado proviene de una máquina o de un humano. Debido a su trabajo en este campo se le considera el padre de la Inteligencia Artificial.\n","\n","<br>\n","\n","**Estado del arte**\n","\n","De acuerdo a su objetivo inicial (simular las capacidades humanas) la AI a la fecha ha llegado a la capacidad de realizar algunas tareas difíciles generando soluciones repetitivas. Sin embargo, los avances de la AI han sido gigantes. La AI ha permeado diferentes aspectos de nuestras vidas, y lo ha hecho de forma tan natural que algunas veces ni siquiera sospechamos que hacemos uso de tecnologías basdas en este principio.\n","\n","<br>\n","\n","**Algunos Ejemplos**\n","\n","  1) Aplicaciones Diarias\n","\n","  * Clasificación de Spam en los emails\n","\n","  ![](https://drive.google.com/uc?id=1sn949OAO1r0dLIYAwXwsTqsHn0_2Hjjb)\n","\n","<br>\n","\n","  * Sugerencias de Netflix\n","  \n","  ![](https://drive.google.com/uc?id=1x2qTpa4L7sXxCnFQtI54mzqTyPCXvcEl)\n","\n","<br>\n","\n","2) Aplicaciones en Ciencia\n","\n","  * Búsqueda eficiente de candidatos a medicamentos.\n","  \n","  ![picture](https://drive.google.com/uc?id=1J4P54FRtNluvcWUn6A0sjtdrHEqQbgH1)\n","\n","<br>\n","\n","  * Segmentación de elementos quirúrgicos - [CinfonIA](https://cinfonia.uniandes.edu.co/)\n","  \n","  ![picture](https://drive.google.com/uc?id=10RCrH1iVgi5rjGhvT54wd1aWCU-tdXC4)\n","\n","<br>\n","\n","3) Aplicaciones en Ilustración y Arte\n","\n","  * Copiando estilos\n","\n","  ![pictures](https://drive.google.com/uc?id=1uR1miqmQTsNiYg3Qvl65htlG9JrkXiZJ)\n","\n","<br>\n","\n","  * Diseño de Fondos (NVIDIA) - [GauGAN](http://nvidia-research-mingyuliu.com/gaugan/)\n","\n","  ![pictures](https://drive.google.com/uc?id=1Vd6-cpJtaS696GA2u4he8f1RrR4y2Apm)\n","\n","<br>\n","\n","  * Creación Artificial de Rostros - [This person does not exists](https://thispersondoesnotexist.com/)\n","\n","  ![pictures](https://drive.google.com/uc?id=1JL_NGHjvwnEGOuItjfakW2YooYTT6i03)\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"RdNOsVxiPc7L"}},{"cell_type":"markdown","source":["# Machine Learning (ML)\n","\n","El ML es un conjunto de algoritmos que tienen como objetivo la construcción de un modelo de aprendizaje entrenado, validado y testeado con datos previamente *procesados*. El modelo resultante del ciclo entrenamiento-validación-testeo es utilizado posteriormente con nuevos datos para realizar predicciones o tomar decisiones con base a la tarea explicita para la que fue diseñado el modelo.\n","\n","<br>\n","\n","En la etapa de entrenamiento el modelo aprende los features (caracteríísticas) de un conjunto de datos conocido como *datos de entrenamiento*, el modelo es mejorado (modificando los parametros del algoritmo) con un conjunto de *datos de validación* y finalmente evaluado (utilizando los parametros con los que se obtuvieron los mejores resultados) con *datos de testeo*. Estos tres conjuntos de datos son completamente diferentes, lo que garantiza que el algoritmo no esta repitiendo lo aprendido con los datos de entrenamiento, si no que realmente es capaz de extrapolar resultados para datos nuevos.\n","\n","<br>\n","\n","Existen dos mecanismos principales de ML:\n","\n","  * Supervised (Supervisado)\n","\n","    Consiste de algoritmos en los que los datos están etiquetados, es decir, un dato tiene una etiqueta que lo caracteriza. Esta etiqueta puede ser un clase (manzada, limón, tomáte) o un valor numérico. El objetivo del algoritmo es predecir la etiqueta que representa a un objeto dependiendo de los features del mismo. Este tipo de algortimos comunmente realizan tareas de **regresión** o **clasificación**.\n","\n","    ![](https://drive.google.com/uc?id=1HX4tsR5Ip9qHjg88SZGjarjnjWZD1yyw)\n","\n","  * Unsupervised (No Supervisado)\n","\n","    En constraste con el mecanismo supervisado, en el *no supervisado* el algoritmo no conoce las etiquetas de los datos y usa unicamente los features para tratar de identificar patrones. Comunmente este tipo de algortimos son usados para visualizar grandes volumenes de datos con alta dimensionalidad en espacios reducidos (**reducción de dimensionalidad**) e identificar agrupamientos de datos (**clustering**).\n","\n","    ![](https://drive.google.com/uc?id=1F3la5dHv9GH0tInKlGpwX4FVrHI7UXWd)\n","\n"],"metadata":{"id":"NVKy3IsNPp3b"}},{"cell_type":"markdown","source":["# Deep Learning (DL)\n","\n","El DL es un conjunto de algoritmos de ML basados en **redes neuronales** que usa progresivamente multiples capas con la capacidad de extraer representaciones desde un bajo hasta un alto nivel a partir de la manipulación de los datos en crudo.\n","\n","La siguiente imagen ilustra un claro ejemplo de extracción de features. Mientras las primeras capas extraen patrones simples (diagonales, horizontales, circulos) las capas más profundas pueden identificar conceptos relevantes para un humano tal como partes de una cara.\n","\n","![](https://drive.google.com/uc?id=1l3vWmQWCQoF_406USXGOPXLFfJffDieV)\n","\n","\n","Existen diferentes estructuras de Redes Neuronales y estas dependen de la tarea para la que fue diseñada.\n","* Deep neural networks\n","* Deep belief networks\n","* Deep reinforcement learning\n","* Recurrent neural networks\n","* **Convolutional neural networks**\n","\n","<br>\n","\n","Al igual que los algoritmos de ML los métodos de DL son utilizados en tareas de **regresión** y **clasificación**, así como también son empleados para **reducción de dimensionalidad** y **clustering**.\n","\n","\n","##Transferencia de Aprendizaje\n","\n","A diferencia de los algoritmos de ML los algoritmos de DL pueden ser reutilizados para nuevas tareas. Dado que los modelos de DL aprenden features a diferentes niveles en cada capa, la información localizada en cada capa (pesos, *weights*) pueden ser **transferidos** para resolver problemas nuevos sin la necesidad de entrenar desde cero. Esta técnica es conocidad como *Transfer Learning*.\n","\n","## Redes Adversariales Generativas\n","\n","Una de las aplicaciones más interesantes en el DL son las redes adversariales generativas (GANs - Generative Adversarial Networks), un par de redes que compiten mutuamente para generar datos nuevos que se parezcan a los reales. Mientras una red genera datos nuevos, la otra red discrimina la calidad del dato generado. El objetivo es que la red generadora produzca datos tan parecidos a los reales que la red discriminadora crea que es un dato real.\n","\n","## Algunos Ejemplos\n","\n","El DL tiene una gran variedad de aplicaciones, dentro de las más destacadas se encuentran: computer vision (CV), speech recognition (SR), natural language processing (NLP), machine translation (MT), bioinformatics, drug design, medical image analysis. Los resultados obtenidos utilizando DL son comparables e incluso sobrepasan los resultados de humanos expertos."],"metadata":{"id":"ougVPLZ0PtEL"}},{"cell_type":"markdown","source":["# Redes Neuronales Artificiales (ANN)\n","\n","# Importancia de las Redes Neuronales\n","\n","El desarrollo de esta tecnología fue un paso gigantesco en la resolución de multiples tareas basadas en algoritmos. Los primeros artículos que describieron el comportamiento de las ANN fueron escritos en la decada de los 70, pero fue 40 años depués que se desarrollo la tecnología que las soportaría. En adición al incremento en el poder computacional y mejoras en el cálculo en paralelo las ANN se han beneficiado de la colección de masivas cantidades de datos; algunos conjuntos de datos basados en imáágenes como [CIFAR100](https://www.cs.toronto.edu/~kriz/cifar.html), [COCO](https://cocodataset.org/#home) o [Imagenet](https://image-net.org/).\n","\n","![](https://drive.google.com/uc?id=1JJ6en7t-Kj_gxgxz58eL1GIaTUkE1iVb)\n","![](https://image-net.org/static_files/index_files/logo.jpg)\n","\n","Esta combinación de factores ha permitido el avance acelerado de las ANN conviritiendolas en herramientas fundamentales de estudio, investigación y desarrollo. El poder de las ANN ha sido demostrado en diferentes tipos de aplicaciones que varían desde tareas de reconocimiento de imágenes hasta el desarrollo de nuevos medicamentos. Las ANN se han convertido en un componente transversal de las ciencias, tanto sociales como naturales.\n","\n","Una de las grandes ventajas de las ANN es que son capaces de analizar diferentes fuentes de datos, desde texto (en una rama llamada procesamiento de lenguaje natural - NLP) hasta imágenes e imágenes enriquecidas (vídeo) (en una rama llamada visión por computador CV).\n","\n","# ¿Qué es una red neuronal?\n","\n","## Unidad Neuronal\n","\n","Las redes neuronales artificiales son el núcleo del DL. La primera red neuronal fue inspirada en el mecanismo de funcionamiento de las neuronas biológicas. La unidad fundamental de una red neuronal es la neurona. Tanto la red neuronal biológica como la red neuronal artificial están compuestas por esta unidad fundamental. Esta comparación suele ser un poco superficial y una mejor forma de entender una neurona es como si se tratase de una función matemática, que para una entrada dada se obtiene una salida. La siguiente Figura muestra una comparación simple entre una neurona biológica y una neurona artificial (perceptron).\n","\n","![](https://drive.google.com/uc?id=1zgR8ylyTorettD9MpmBaZejaTZjh8SQz)\n","\n","*Similarity between biological and artificial neural networks (Arbib, 2003a; Haykin, 2009b).*\n","\n","<br>\n","\n","## El Perceptron\n","\n","El **perceptron** está compuesto por diferentes elementos en dos zonas de transformación. *Input* son los datos recibidos por el perceptron. Cada dato es ponderado por un peso (*weight*) $w_{n}$. Los productos entre las entradas $x$ y los pesos $w$ es sumado lineamente junto a un valor constante conocido como *bias*, así $z = \\Sigma x_n w_{n} + b$ (Transformación lineal). El resultado pasa por una función no lineal, conocida como función de activación que se activará o no dependiendo del valor de la suma obteniendo una salida *out* (Transformación no-lineal). Esta activación nos permite saber si la salida coincide o no con lo esperado y para ello calculamos un error, definido como la diferencia entre lo esperado y lo obtenido, $\\Delta = y - \\bar{y}$. Este error nos sirve para actualizar los pesos, cada vez que se obtiene una salida del perceptron se dice que ha ocurrido una época, después de cada época los pesos se actualizan así $w_n = w_n + \\eta*\\Delta*x_n$, donde $\\eta$ es un parametro conocido como la tasa (rata) de aprendizaje (*learning rate*).\n","\n","![](https://drive.google.com/uc?id=14wIrtX0jvqUxSWJvN6crzDFlj0mrI-JX)\n"],"metadata":{"id":"cQ048DU6Q7aP"}},{"cell_type":"markdown","source":["# Ejercicio\n","\n","En este notebook escribiremos el código de un Perceptron, el modelo más sencillo de una neurona y base de las ANN."],"metadata":{"id":"_50jkWZuRAi4"}},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv('percep_linear.csv')\n","data.head()"],"metadata":{"id":"fysWS1l8RBxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x1 = data['X1']\n","x2 = data['X2']\n","y = data['Y']\n","\n","class_0 = y == 0 # Esto es una máscara\n","class_1 = y == 1 # Esto es una máscara\n","\n","#-- Graficamos los puntos con sus correspondientes clases\n","fig = plt.figure(figsize=(4,4))\n","plt.plot(x1[class_0],x2[class_0],'o', c='black', label='0')\n","plt.plot(x1[class_1],x2[class_1],'o', c='red', label='1')\n","plt.xlim(0,1)\n","plt.ylim(0,1)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"z0F7_OHDRDF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Definimos nuestra función de activación, en este caso usamos un Sigmoide\n","def act(z):\n","  return 1/(1 + np.exp(-z))"],"metadata":{"id":"LbDG59ILRJZG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Otros ejemplos de funciones de activación...\n","\n","![](https://drive.google.com/uc?id=1MfiAmY-UbwL-igrgrmCdvMCzTSrQ2Ljw)\n","\n","![](https://drive.google.com/uc?id=1TN_ewINFbo3JBZIZUn302_IBTBaRfLOI)"],"metadata":{"id":"402CPvKmRMEd"}},{"cell_type":"code","source":["#-- Definimos el Perceptron\n","\n","# Inicializamos los pesos en 0\n","b = 0\n","w_1 = 0\n","w_2 = 0\n","\n","# Inicializamos el número de épocas y la rata de aprendizaje\n","n_epochs = 15 # Número de épocas\n","n = 0.5      # Tasa de aprendizaje\n","\n","# Esta es la función nuestro perceptron encontrará al final de todas las épocas\n","def y(x):\n"," return -(b + w_1*x)/w_2\n","\n","# Entrenamos el Perceptron\n","for epoch in range(n_epochs):\n","  for i,j,k in zip(x1,x2,Y):\n","\n","    # Función de Suma\n","    z = i*w_1 + j*w_2 + b\n","\n","    # Función de Activación\n","    sig_z = act(z)\n","\n","    # Evaluamos la salida (output)\n","    if sig_z >= 0.5:\n","      out = 1\n","    if sig_z < 0.5:\n","      out = 0\n","\n","    # Calculamos el error\n","    error = k - out\n","\n","    # Actualizamos los pesos\n","    b = b + n*error\n","    w_1 += n*error*i\n","    w_2 += n*error*j\n","\n","  print('Epoch [{}/{}], bias: {}, w1: {}, w2: {}'.format(epoch+1,n_epochs,b,w_1,w_2))\n","\n","  fig = plt.figure(figsize=(4,4))\n","  plt.plot(x1[class_0],x2[class_0],'o', c='black', label='0')\n","  plt.plot(x1[class_1],x2[class_1],'o', c='red', label='1')\n","  plt.plot(np.sort(x1),y(np.sort(x1)),'-', c='green',)\n","  plt.xlim(0,1)\n","  plt.ylim(0,1)\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"R2_ZV3aeRNsu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Perceptron de Multiples Capas - MLP\n","\n","Los perceptrones multicapas son un tipo de ANN fromada por múúltiples capas de neurinas, de tal manera que tiene capacidad para resolver problemas que no son linealmente separables, lo cual es la principal limitación del perceptrón.\n","\n","Los perceptrones de multiples capas son conjuntos de perceptrones conectados, donde la salida de un perceptron en una de las capas es la entrada para una neurona en la siguiente capa. Esta estrategia permite extraer una representación fina de la información que entra a la ANN.\n","\n","Los datos en la entrada pasan por un conjunto de capas de neuronas (llamadas capas ocultas) la salida de este conjunto de capas son la entrada para una neurona de salida de la cual obtenemos un único resultado. La siguiente Figura esquematiza la forma en que la información pasa a través de cada neurona en diferente capas.\n","\n","![](https://drive.google.com/uc?id=1qtVjikjui3DqybyiH4ndbL9mS65T4zmx)\n","\n","\n","De la misma forma en la que un perceptron actualiza sus pesos, los MLP actualizan los pesos de todas sus neuronas en un proceso llamado *backpropagation* (o retropropagación). Este proceso es hecho por el *optimizador* que se encarga de calcular el gradiente de la función de error por cada peso de la red, estos pesos son actualizados en cada época y el objetivo es minimizar el error.\n","\n","![](https://drive.google.com/uc?id=15PgGM3v_m8qYENE96uOJrD29_o8p6kLq)\n","\n","Las ANN modernas usan una combinación de multiples capas y reciben el nombre de redes neuronales profundas (\"Deep neural networks\").\n"],"metadata":{"id":"UVk9liw8QHV-"}},{"cell_type":"markdown","source":["# Ejercicio\n","\n","En este ejercicio usaremos el dataset de [red wine quality](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) para clasificar el vino entre vino de alta calidad y vino de baja calidad usando todos lo features del dataset. El modelo que usaremos será un [Multi Layer Perceptron Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) del paquete [scikitlearn](https://scikit-learn.org/)."],"metadata":{"id":"zxg1dAutQKcN"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"GZC4Hn2xG2zt","executionInfo":{"status":"error","timestamp":1698026282400,"user_tz":300,"elapsed":994,"user":{"displayName":"JOHN FREDY SUAREZ PEREZ","userId":"07610715876772400534"}},"outputId":"7495e8e9-4483-42db-d7ec-23652aa92a39"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5637c16c3283>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'winequality-red.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#-- Identificamos los nombres de las columnas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'winequality-red.csv'"]}],"source":["#--- Leemos los datos con pandas\n","import pandas as pd\n","\n","data = pd.read_csv('winequality-red.csv')\n","\n","#-- Identificamos los nombres de las columnas\n","data.keys()"]},{"cell_type":"code","source":["#-- Cargamos los features y los objetivos\n","\n","X = data.drop(['quality'], axis = 'columns')\n","Y = data['quality']"],"metadata":{"id":"dg1nLG7aQMbY","executionInfo":{"status":"aborted","timestamp":1698026282403,"user_tz":300,"elapsed":20,"user":{"displayName":"JOHN FREDY SUAREZ PEREZ","userId":"07610715876772400534"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Visualizamos los objetivos en un histograma\n","\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure(figsize=(7,5))\n","plt.hist(Y)\n","plt.ylabel('Counts')\n","plt.xlabel('quality')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"id":"pLJMxMNvQNXf","executionInfo":{"status":"error","timestamp":1698026286624,"user_tz":300,"elapsed":248,"user":{"displayName":"JOHN FREDY SUAREZ PEREZ","userId":"07610715876772400534"}},"outputId":"2c0df5c4-2ad8-4fab-9eb3-90bf7271a71a"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a13e68db7635>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Counts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 700x500 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["#-- Convertimos nuestro objetivo en un problema binario\n","\n","import numpy as np\n","Y = np.array(Y)\n","\n","Y[Y<6] = 0\n","Y[Y>=6] = 1\n","\n","\n","fig = plt.figure(figsize=(7,5))\n","plt.hist(Y)\n","plt.ylabel('Counts')\n","plt.xlabel('quality')\n","plt.show()"],"metadata":{"id":"_3i6wA0qQOvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Dividimos nuestro dataset en Train/Test\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"],"metadata":{"id":"eSmXe2C7QQ49"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Cargamos MLPCLassifier para buscar un modelo\n","\n","from sklearn.neural_network import MLPClassifier\n","\n","model = MLPClassifier(activation='relu',  hidden_layer_sizes=(2, 2), solver='adam', learning_rate_init=0.1)\n","model"],"metadata":{"id":"LFv6tntMQRtu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Entrenamos el modelo y realizamos una predicción\n","\n","model.fit(X_train,Y_train)\n","Y_pred = model.predict(X_test)"],"metadata":{"id":"4eh3fY98QStP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_pred"],"metadata":{"id":"kBXD2oPEQTuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Evaluamos el modelo con el accuracy_score\n","from sklearn.metrics import accuracy_score\n","\n","accuracy_score(Y_pred,Y_test)"],"metadata":{"id":"moHqFprKQVFp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Arquitectura de Una Red Neuronal\n","\n","En resumen, la arquitectura de una ANN está definida por el número y la forma de sus capas. En el estado del arte de estas ANN esas arquitecturas suelen ser un poco complejas, con algunas capas saltando sobre otras capas o capas que retornan información de regreso a capas anteriores.\n","\n","En este notebook veremos un ejemplo sencillo de una ANN y cual es la función de cada una de las capas que la componen. Para diseñar esta ANN usaremos el framework [PyTorch](https://pytorch.org/) y el dataset estándar para la clasificación de tres especies de flores [IRIS](https://archive.ics.uci.edu/ml/datasets/Iris)."],"metadata":{"id":"u43BfWStQXS3"}},{"cell_type":"markdown","source":["# Ejercicio\n","\n","En este notebook construiremos una ANN sencilla para hacer un ejercicio de clasificación usando el dataset [IRIS](https://archive.ics.uci.edu/ml/datasets/Iris)."],"metadata":{"id":"6UuH2M2xQf9Y"}},{"cell_type":"code","source":["#--- Importamos paquetes escenciales\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"D0zdArPhQdpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","iris = load_iris()\n","iris.keys()"],"metadata":{"id":"VB2IUwPDQk-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Extraemos la infromación más importante\n","X = iris['data']\n","Y = iris['target']\n","names = iris['target_names']\n","feature_names = iris['feature_names']\n","\n","#-- Normalizamos los datos para que tengan media 0 y desviación 1\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","#-- Dividimos los datos entre un conjunto de entrenamiento y testeo\n","X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n","\n","#-- Visualizamos el tamaño de los datos de entrenamiento\n","np.shape(X_train)"],"metadata":{"id":"rlsWpbGsQm_i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--Visualizamos los datos\n","class0 = Y == 0\n","class1 = Y == 1\n","class2 = Y == 2\n","\n","\n","fig = plt.figure(figsize=(10,5))\n","plt.subplot(1,2,1)\n","plt.plot(X_scaled[:,0][class0],X_scaled[:,1][class0],'o',c='red', label=names[0])\n","plt.plot(X_scaled[:,0][class1],X_scaled[:,1][class1],'o',c='blue', label=names[1])\n","plt.plot(X_scaled[:,0][class2],X_scaled[:,1][class2],'o',c='green', label=names[2])\n","plt.grid()\n","plt.legend()\n","plt.xlabel(feature_names[0])\n","plt.ylabel(feature_names[1])\n","plt.subplot(1,2,2)\n","plt.plot(X_scaled[:,2][class0],X_scaled[:,3][class0],'o',c='red', label=names[0])\n","plt.plot(X_scaled[:,2][class1],X_scaled[:,3][class1],'o',c='blue', label=names[1])\n","plt.plot(X_scaled[:,2][class2],X_scaled[:,3][class2],'o',c='green', label=names[2])\n","plt.grid()\n","plt.legend()\n","plt.xlabel(feature_names[2])\n","plt.ylabel(feature_names[3])\n","plt.show()"],"metadata":{"id":"Jvsez6I7QpA5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Artificial Neural Network con Pytorch\n","\n","Vamos a crear una ANN de 3 capas lineales, las dos primeras tendrán funciones de activación tipo ReLU y la última una función de activación tipo Softmax."],"metadata":{"id":"iBJl9pJfQsPa"}},{"cell_type":"code","source":["#--- Importamos el paquete torch\n","import torch\n","from torch.autograd import Variable # Para convertir los datos a tensores\n","\n","#--- Definimos la secuencia de capas de la ANN\n","input_dim = X_train.shape[1]\n","model = torch.nn.Sequential(\n","                torch.nn.Linear(input_dim, 50),\n","                torch.nn.ReLU(),\n","                torch.nn.Linear(50, 50),\n","                torch.nn.ReLU(),\n","                torch.nn.Linear(50, input_dim),\n","                torch.nn.Softmax(dim=1)\n","                )\n","model"],"metadata":{"id":"gWU-FUmfQs1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Definimos el optimizador y el criterio de evaluación\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"Xfhs-B1BQvAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Definimos el número de épocas\n","\n","n_epoch  = 100\n","\n","#-- Convertimos los datos a tensores\n","X_train_tensor = Variable(torch.from_numpy(X_train)).float()\n","Y_train_tensor = Variable(torch.from_numpy(Y_train)).long()\n","X_test_tensor  = Variable(torch.from_numpy(X_test)).float()\n","Y_test_tensor  = Variable(torch.from_numpy(Y_test)).long()\n","\n","#-- Definimos párametros para almacenar la evalaución el entrenamiento de la red en función del número de épocas\n","loss_list     = np.zeros(n_epoch)\n","accuracy_list = np.zeros(n_epoch)\n","\n","#-- Iniciamos el entrenamiento\n","for epoch in range(n_epoch):\n","    Y_pred = model(X_train_tensor)\n","    loss = criterion(Y_pred, Y_train_tensor)\n","    loss_list[epoch] = loss.item()\n","\n","    # Gradiente Cero\n","    optimizer.zero_grad()\n","\n","    # Backpropagation\n","    loss.backward()\n","\n","    # Nuevo paso\n","    optimizer.step()\n","\n","    correct = (torch.argmax(Y_pred, dim=1) == Y_train_tensor).type(torch.FloatTensor)\n","    accuracy_list[epoch] = correct.mean()\n","\n","    print('Epoch [{}/{}], loss: {}, acc: {}'.format(epoch+1,n_epoch,loss_list[epoch],accuracy_list[epoch]))"],"metadata":{"id":"24SCAfIFQwUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Graficamos la precisión y la perdida para el set de entrenamiento\n","fig = plt.figure(figsize=(10, 4))\n","plt.subplot(1,2,1)\n","plt.plot(accuracy_list)\n","plt.ylabel(\"training accuracy\")\n","plt.xlabel(\"epcohs\")\n","plt.grid()\n","\n","plt.subplot(1,2,2)\n","plt.plot(loss_list)\n","plt.ylabel(\"training loss\")\n","plt.xlabel(\"epochs\")\n","plt.grid()\n","plt.show()"],"metadata":{"id":"C9Lq9lzJQxud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Evaluamos con el set de testeo\n","\n","Y_pred = model(X_test_tensor)\n","loss = criterion(Y_pred, Y_test_tensor)\n","correct = (torch.argmax(Y_pred, dim=1) == Y_test_tensor).type(torch.FloatTensor)\n","\n","print('Loss: {}, Acc:{}'.format(loss, correct.mean()))"],"metadata":{"id":"Z8WmZbPzQzHe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Imágenes como conjuntos de datos\n","\n","Las imágenes son un tipo de datos fundamental para un cientifíco de datos que resuelve tareas de visión por computador. A diferencia de otro tipo de datos las imágenes son multidimensionales y contienen información enriquecida además de unicamente su tamaño (alto x ancho). Cada pixel contiene tambiéén la información de su intensidad, de modo que un objeto tipo imagen tiene un tamaño (alto,ancho) y por cada coordenada un valor de intensidad en una escala de 0 a 1.\n","\n","![](https://drive.google.com/uc?id=1-CFgFy0f6Mkb0496sb4MgR60SoCX-F9_)\n","\n","\n","Por otro lado las imágenes a color tienen 3 canales diferentes (asociado a las escalas RGB - Rojo, Verde y azul), de modo que el tamaño de un objeto tipo imagen a color es (alto, ancho, canales) donde cada pixel contiene la información de intensidad en las escalas rojo, azul y verde. Esta escala varía entre 0 y 255 a diferencia de la escala de grises.\n","\n","\n","![](https://drive.google.com/uc?id=18Txu65iVgA08Gq7xjLxZp8s3A3N1GnEp)\n","\n","\n","Algunas imágenes continen un cuarto canal asociado al brillo de cada pixel, en este caso en nemero de canales es 4 y se les reconoce como las escalas RGBA.\n","\n"],"metadata":{"id":"0lRr3XF2RiZs"}},{"cell_type":"markdown","source":["# Ejercicio\n","\n","En este notebook identificaremos uno de los errores más comúnes al momento de entrenar modelos de aprendizaje; el cruce de datos de entrenamiento y evaluación.\n","\n","Para identificar este error visualizaremos curvas de *loss*, *f1_score* y *accuracy*."],"metadata":{"id":"3knYQ2nqRk4r"}},{"cell_type":"markdown","source":["## Leer los datos tipo imágenes"],"metadata":{"id":"pF4t7JtzRm37"}},{"cell_type":"code","source":["#-- Descomprimimos el dataset\n","# !rm -r mnist\n","# !unzip mnist.zip"],"metadata":{"id":"_ArZPQJwRoVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Buscamos las direcciones de cada archivo de imagen\n","from glob import glob\n","\n","train_files = glob('./mnist/train/*/*.png')\n","valid_files = glob('./mnist/valid/*/*.png')\n","test_files = glob('./mnist/test/*/*.png')\n","\n","train_files[0]"],"metadata":{"id":"lFfL8x8LRpm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Ordenamos los datos de forma aleatoria para evitar sesgos\n","import numpy as np\n","\n","np.random.shuffle(train_files)\n","np.random.shuffle(valid_files)\n","np.random.shuffle(test_files)\n","\n","len(train_files), len(valid_files), len(test_files)"],"metadata":{"id":"c0nid1k3Rqjt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Primer caso: Sin cruce"],"metadata":{"id":"75sl1yx2RtAq"}},{"cell_type":"code","source":["#--- Cargamos los datos de entrenamiento en listas\n","from PIL import Image\n","\n","N_train = len(train_files)\n","X_train = []\n","Y_train = []\n","\n","for i, train_file in enumerate(train_files):\n","  Y_train.append( int(train_file.split('/')[3]) )\n","  X_train.append(np.array(Image.open(train_file)))"],"metadata":{"id":"hIFhLqV9Rt6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Cargamos los datos de validación en listas\n","N_valid = len(valid_files)\n","X_valid = []\n","Y_valid = []\n","\n","for i, valid_file in enumerate(valid_files):\n","  Y_valid.append( int(valid_file.split('/')[3]) )\n","  X_valid.append( np.array(Image.open(valid_file)) )"],"metadata":{"id":"JNIyN_JlRvG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Cargamos los datos de testeo en listas\n","N_test = len(test_files)\n","X_test = []\n","Y_test = []\n","\n","for i, test_file in enumerate(test_files):\n","  Y_test.append( int(test_file.split('/')[3]) )\n","  X_test.append( np.array(Image.open(test_file)) )"],"metadata":{"id":"n2Z7a6XLRwmD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Visualizamos el tamaño de cada subset\n","len(X_train), len(X_valid), len(X_test)"],"metadata":{"id":"v4B6SkDbRx5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Visualizamos la distribución de clases en cada subset\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure(figsize=(15,5))\n","plt.subplot(1,3,1)\n","plt.hist(np.sort(Y_train))\n","plt.xlabel('class')\n","plt.ylabel('counts')\n","plt.title('Train set')\n","\n","plt.subplot(1,3,2)\n","plt.hist(np.sort(Y_valid))\n","plt.xlabel('class')\n","plt.ylabel('counts')\n","plt.title('Valid set')\n","\n","plt.subplot(1,3,3)\n","plt.hist(np.sort(Y_test))\n","plt.xlabel('class')\n","plt.ylabel('counts')\n","plt.title('Test set')\n","\n","plt.show()"],"metadata":{"id":"a7KFKp0RRy3J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Este dataset cuenta con un total de 900 objetos por clase (600 para entrenamiento, 200 para validación y 100 para testeo), este es un ejemplo donde las clases están balanceadas, no siempre se tendrán datos de esta forma.\n","\n","Considerando el total de datos de este dataset,~66% son datos de entrenamiento, otro ~22% de validación y un ~11% para testeo. Esto representa un buen ejemplo de cómo distribuir los datos para entrenar sus modelos."],"metadata":{"id":"B7JL5hPQR1FD"}},{"cell_type":"code","source":["#-- Visualizamos los datos\n","fig = plt.figure(figsize=(8,8))\n","for i in range(4):\n","  plt.subplot(2,2,i+1)\n","  plt.imshow(X_test[i*15])\n","  plt.title(Y_test[i*15])\n","  plt.axis(False)\n","plt.show()"],"metadata":{"id":"S-x4w9gdR2gJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Convertimos las listas de datos a tensores de torch\n","import torch\n","from torch.autograd import Variable\n","\n","X_train = Variable(torch.from_numpy(np.array(X_train))).float()\n","Y_train = Variable(torch.from_numpy(np.array(Y_train))).long()\n","\n","X_valid = Variable(torch.from_numpy(np.array(X_valid))).float()\n","Y_valid = Variable(torch.from_numpy(np.array(Y_valid))).long()\n","\n","X_test = Variable(torch.from_numpy(np.array(X_test))).float()\n","Y_test = Variable(torch.from_numpy(np.array(Y_test))).long()\n","\n","X_train.data.size()"],"metadata":{"id":"5tezKSiVR4At"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Definimos una ANN con dos capas ocultas lineales de 100 neuronas\n","\n","input_dim = 28*28\n","out_dim = 10\n","hidden = 100\n","\n","model = torch.nn.Sequential(\n","  torch.nn.Linear(input_dim, hidden),\n","  torch.nn.ReLU(),\n","  torch.nn.Linear(hidden, out_dim)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"Fuo_MuVeR50t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score # Nueva métrica (La revisaremos la próóxima sesión)\n","\n","#-- Número de épocas\n","n_epoch = 100\n","\n","#-- Listas de evaluación entrenamiento\n","loss_train = []\n","f1_train = []\n","acc_train = []\n","\n","#-- Listas de evaluación validación\n","loss_valid = []\n","f1_valid = []\n","acc_valid = []\n","\n","#-- Entrenamineto de la ANN\n","for epoch in range(n_epoch):\n","  model.train()\n","\n","  Xtr = X_train.view(X_train.size(0), -1)\n","  Y_pred = model(Xtr)\n","\n","  loss = criterion(Y_pred,Y_train)\n","  loss_train.append(loss.item())\n","\n","  Y_pred = torch.argmax(Y_pred, 1)\n","  f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n","\n","  acc = sum(Y_train == Y_pred)/len(Y_pred)\n","  acc_train.append(acc)\n","\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","  print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch,loss_train[-1], f1_train[-1], acc_train[-1]) )\n","\n","  model.eval()\n","  Xvl = X_valid.view(X_valid.size(0), -1)\n","  Y_pred = model(Xvl)\n","  loss = criterion(Y_pred,Y_valid)\n","  loss_valid.append(loss.item())\n","\n","  Y_pred = torch.argmax(Y_pred, 1)\n","  f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n","\n","  acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","  acc_valid.append(acc)"],"metadata":{"id":"cS1uXkKIR7QD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Visualizamos las curvas de entrenamiento y validación\n","\n","fig = plt.figure(figsize=(15,5))\n","plt.subplot(1,3,1)\n","plt.plot(range(n_epoch), loss_train, label='train')\n","plt.plot(range(n_epoch), loss_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.grid()\n","plt.subplot(1,3,2)\n","plt.plot(range(n_epoch), f1_train, label='train')\n","plt.plot(range(n_epoch), f1_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('f1_score')\n","plt.legend()\n","plt.grid()\n","plt.subplot(1,3,3)\n","plt.plot(range(n_epoch), acc_train, label='train')\n","plt.plot(range(n_epoch), acc_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.grid()\n","\n","plt.savefig('./curves_ok.png', bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"O-HTsdBdR9UR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Evaluamos el modelo entrenado con el set de testeo\n","\n","model.eval()\n","\n","Xts = X_test.view(X_test.size(0), -1)\n","Y_pred = model(Xts)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"],"metadata":{"id":"TLaT3MY6R_fA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Overfitting y Regularización\n","\n","El **overfitting** o sobreajuste es otro problema común al entrenar un modelo de aprendizaje automático. Consiste en entrenar modelos que aprenden a la perfección los datos de entrenamiento, perdiendo de esta forma generalidad. De modo, que si al modelo se le pasan datos nuevos que jamás ha visto, no será capaz de realizar una buena predicción.\n","\n","Existe un problema opuesto al overfitting conocido como **underfitting** o subajuste, en el que el modelo no logra realizar una predicción ni siquiera cercana a los datos de entrenamiento y esta lejos de hacer una generalización.\n","\n","![](https://drive.google.com/uc?id=15e1qtMWMYJA4HAc8eAhOt90DWMzeYEeG)\n","\n","Para evitar el underfitting y el overfitting se pueden utilizar curvas de **loss**, **f1_score** o **accuracy** utilizando los datos de entrenamiento y validación. Haciendo un análisis sobre estas curvas se logra identificar estos problemas."],"metadata":{"id":"AGaotb-AT28R"}},{"cell_type":"code","source":["#--- Definimos una función que nos permita entrenar diferentes modelos de ANN\n","\n","from sklearn.metrics import f1_score\n","\n","def train_valid(model, n_epoch, optimizer, criterion):\n","  loss_train = []\n","  f1_train = []\n","  acc_train = []\n","\n","  loss_valid = []\n","  f1_valid = []\n","  acc_valid = []\n","\n","  for epoch in range(n_epoch):\n","    model.train()\n","\n","    Xtr = X_train.view(X_train.size(0), -1)\n","    Y_pred = model(Xtr)\n","\n","    loss = criterion(Y_pred,Y_train)\n","    loss_train.append(loss.item())\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n","\n","    acc = sum(Y_train == Y_pred)/len(Y_pred)\n","    acc_train.append(acc)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch,loss_train[-1], f1_train[-1], acc_train[-1]) )\n","\n","    model.eval()\n","    Xvl = X_valid.view(X_valid.size(0), -1)\n","    Y_pred = model(Xvl)\n","    loss = criterion(Y_pred,Y_valid)\n","    loss_valid.append(loss.item())\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n","\n","    acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","    acc_valid.append(acc)\n","\n","  fig = plt.figure(figsize=(15,5))\n","  plt.subplot(1,3,1)\n","  plt.plot(range(n_epoch), loss_train, label='train')\n","  plt.plot(range(n_epoch), loss_valid, label='valid')\n","  plt.xlabel('n_epoch')\n","  plt.ylabel('loss')\n","  plt.legend()\n","  plt.grid()\n","  plt.subplot(1,3,2)\n","  plt.plot(range(n_epoch), f1_train, label='train')\n","  plt.plot(range(n_epoch), f1_valid, label='valid')\n","  plt.xlabel('n_epoch')\n","  plt.ylabel('f1_score')\n","  plt.legend()\n","  plt.grid()\n","  plt.subplot(1,3,3)\n","  plt.plot(range(n_epoch), acc_train, label='train')\n","  plt.plot(range(n_epoch), acc_valid, label='valid')\n","  plt.xlabel('n_epoch')\n","  plt.ylabel('accuracy')\n","  plt.legend()\n","  plt.grid()"],"metadata":{"id":"UXTQwnOdT3S6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Underfitting\n","\n","El **underfitting** o sub ajuste se puede presentar en las siguientes situaciones:\n","\n","* **Finalización temprana**: Cuando el modelo se entrena hasta una época temprana a pesar de que la tendencia indica una posible obtención de mejores resultados.\n","\n","* **Modelo Simple**: Cuando el modelo es tan básico que no es capaz de extraer ningún tipo de patrón efectivo que le permita hacer una generalización de los datos."],"metadata":{"id":"SIVQYxYlT_kE"}},{"cell_type":"code","source":["#--- Definimos una ANN simple para identificar un error de underfitting\n","\n","input_dim = 28*28\n","out_dim = 10\n","\n","model = torch.nn.Sequential(\n","  torch.nn.Linear(input_dim, out_dim)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","train_valid(model,30,optimizer,criterion)"],"metadata":{"id":"SybWJx6TUAzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Evaluamos el modelo entrenado con el set de testeo\n","model.eval()\n","\n","Xts = X_test.view(X_test.size(0), -1)\n","Y_pred = model(Xts)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"],"metadata":{"id":"5ZziEuCMUCFd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Overfitting\n","\n","El **overfitting** o sobreajuste es el caso opuesto al subajuste y se puede presentar en la siguiente situación:\n","una obtención de mejores resultados.\n","\n","* **Modelo Complejo**: El modelo es tan complejo que aprendió perfectamente los datos de entrenamiento, perdiendo generalidad. Cuando el modelo vea datos nuevos, diferentes a los del entrenamiento, su predicción será errónea.\n"],"metadata":{"id":"S0TcunLBUEHI"}},{"cell_type":"code","source":["input_dim = 28*28\n","out_dim = 10\n","hidden = 60\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(input_dim, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, out_dim)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","train_valid(model,100,optimizer,criterion)"],"metadata":{"id":"oOWoWHZLUDVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Evaluamos el modelo entrenado con el set de testeo\n","model.eval()\n","\n","Xts = X_test.view(X_test.size(0), -1)\n","Y_pred = model(Xts)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"],"metadata":{"id":"ceRzy3ihUIdI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Regularización\n","\n","Un mecanismo que permite evitar el sobreajuste es conocido como **regularización**. La cantidad de regularización afectará el rendimiento de validación del modelo. Muy poca regularización no resolverá el problema de sobreajuste. Demasiada regularización hará que el modelo sea mucho menos efectivo. La regularización actúa como una restricción sobre el conjunto de posibles funciones aprendibles.\n","\n","<br>\n","\n","Según [Ian Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow), \"*La regularización es cualquier modificación que hacemos a un algoritmo de aprendizaje que tiene como objetivo reducir su error de generalización pero no su error de entrenamiento.*\"\n","\n","<br>\n","\n","**Regularización de caída de peso**\n","\n","La pérdida de peso es la técnica de regularización más común (implementada en Pytorch). En PyTorch, la caída de peso se proporciona como un parámetro para el optimizador *decay_weight*. En [este](https://pytorch.org/docs/stable/optim.html) enlace se muestran otros parámetros que pueden ser usados en los optimizadores.\n","\n","A la caída de peso también se le llama:\n","  * L2\n","  * Ridge\n","\n","Para la disminución de peso, agregamos un término de penalización en la actualización de los pesos:\n","\n","$w(x) = w(x) − \\eta \\nabla x - \\alpha \\eta x$\n","\n","Este nuevo término en la actualización lleva los parámetros $w$ ligeramente hacia cero, agregando algo de **decaimiento** en los pesos con cada actualización."],"metadata":{"id":"5hrn2JHxUHsd"}},{"cell_type":"code","source":["input_dim = 28*28\n","out_dim = 10\n","hidden = 60\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(input_dim, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, hidden),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(hidden, out_dim)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","train_valid(model,100,optimizer,criterion)"],"metadata":{"id":"4QyfKSswUL2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #-- Evaluamos el modelo entrenado con el set de testeo\n","model.eval()\n","\n","Xts = X_test.view(X_test.size(0), -1)\n","Y_pred = model(Xts)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"],"metadata":{"id":"T-V5YeGhUNo_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exploración de metaparametros\n","\n","Una de las tareas fundamentales al momento de diseñar un modelo de aprendizaje automático es la selección de los parámetros del modelo (metaparámetros), hasta el momento los parámetros que hemos utilizados han sido:\n","\n","* **n_layers** = Número de capas\n","* **n_neurons** = Número de neuronas\n","* **n_epoch** = Número de épocas\n","* **lr** = Tasa de aprendizaje - learning rate\n","* **weight_decay** = peso de decaímiento\n","\n","Sin embargo uno de los metaparámetros más importantes al momento de entrenar una ANN es el tamaño de los datos con el que el modelo aprende. El **batch_size** es un parámetro que regula el tamaño de los datos que el modelo utiliza para entrenarse.\n","\n","* **batch_size** = Tamaño del subconjunto"],"metadata":{"id":"fBEZk3UrUPwI"}},{"cell_type":"markdown","source":["#Ejercicio\n","\n","Utilizar el metaparametro **batch_size** y compare su resultados de *loss*, *f1_score* y *accuracy* para un modelo similar utilizando diferentes épocas."],"metadata":{"id":"PzKLrvJ6URTn"}},{"cell_type":"code","source":["#--- Definimos una ANN simple sin utilizar batch_size\n","\n","input_dim = 28*28\n","out_dim = 10\n","hidden = 50\n","\n","learning_rate = 0.01\n","weight_decay = 0.01\n","\n","model = torch.nn.Sequential(\n","  torch.nn.Linear(input_dim, hidden),\n","  torch.nn.Tanh(),\n","  torch.nn.Linear(hidden, hidden),\n","  torch.nn.ReLU(),\n","  torch.nn.Linear(hidden, hidden),\n","  torch.nn.ReLU(),\n","  torch.nn.Linear(hidden, out_dim)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","criterion = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"h1KDd76oUVNx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelo entrenado en 15 épocas sin batch_size"],"metadata":{"id":"pOQGY1qzUXVA"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","n_epoch = 15\n","\n","loss_train = []\n","f1_train = []\n","acc_train = []\n","\n","loss_valid = []\n","f1_valid = []\n","acc_valid = []\n","\n","for epoch in range(n_epoch):\n","  model.train()\n","  Xtr = X_train.view(X_train.size(0), -1)\n","  Y_pred = model(Xtr)\n","\n","  loss = criterion(Y_pred,Y_train)\n","  loss_train.append(loss.item())\n","\n","  Y_pred = torch.argmax(Y_pred, 1)\n","  f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n","\n","  acc = sum(Y_train == Y_pred)/len(Y_pred)\n","  acc_train.append(acc)\n","\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","  print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch,loss_train[-1], f1_train[-1], acc_train[-1]) )\n","\n","  model.eval()\n","  Xvl = X_valid.view(X_valid.size(0), -1)\n","  Y_pred = model(Xvl)\n","  loss = criterion(Y_pred,Y_valid)\n","  loss_valid.append(loss.item())\n","\n","  Y_pred = torch.argmax(Y_pred, 1)\n","  f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n","\n","  acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","  acc_valid.append(acc)"],"metadata":{"id":"j_xt4g-TUYM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(15,5))\n","plt.subplot(1,3,1)\n","plt.plot(range(n_epoch), loss_train, label='train')\n","plt.plot(range(n_epoch), loss_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.grid()\n","plt.subplot(1,3,2)\n","plt.plot(range(n_epoch), f1_train, label='train')\n","plt.plot(range(n_epoch), f1_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('f1_score')\n","plt.legend()\n","plt.grid()\n","plt.subplot(1,3,3)\n","plt.plot(range(n_epoch), acc_train, label='train')\n","plt.plot(range(n_epoch), acc_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.grid()"],"metadata":{"id":"bmdW7UyUUZjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #-- Evaluamos el modelo entrenado con el set de testeo\n","model.eval()\n","\n","Xts = X_test.view(X_test.size(0), -1)\n","Y_pred = model(Xts)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"],"metadata":{"id":"2_2hL_3bUazD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Batch Size\n","El **batch_size** es un metaparametro que permite seleccionar muestras de datos más pequeñas que el conjunto completo de datos. Usar subconjuntos en el proceso de entrenamiento en vez del conjunto completo, es altamente eficiente desde el punto de vista computacional. De modo que se puede obtener un modelo de igual capacidad usando un menor número de épocas.\n","\n","![](https://drive.google.com/uc?id=1I9R58FoYEr9SGtZfAakwAuwmEk_OnBds)"],"metadata":{"id":"eDs_FZY3UcBc"}},{"cell_type":"markdown","source":["# Modelo entrenado en 5 épocas con batch_size"],"metadata":{"id":"KMdh66l1UeAG"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset\n","\n","batch_size = 512\n","\n","train_ds = TensorDataset(X_train, Y_train)\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"ssY-d06SUez3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Definimos una ANN simple sin utilizar batch_size\n","\n","input_dim = 28*28\n","out_dim = 10\n","hidden = 50\n","\n","learning_rate = 0.01\n","weight_decay = 0.01\n","\n","model = torch.nn.Sequential(\n","  torch.nn.Linear(input_dim, hidden),\n","  torch.nn.Tanh(),\n","  torch.nn.Linear(hidden, hidden),\n","  torch.nn.ReLU(),\n","  torch.nn.Linear(hidden, hidden),\n","  torch.nn.ReLU(),\n","  torch.nn.Linear(hidden, out_dim)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","criterion = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"CNigx2foUfv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_epoch = 5\n","\n","loss_train = []\n","f1_train = []\n","acc_train = []\n","\n","loss_valid = []\n","f1_valid = []\n","acc_valid = []\n","\n","total_it = 0\n","\n","for epoch in range(n_epoch):\n","  for batch_id, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n","    model.train()\n","\n","    Xtr = X_train_batch.view(X_train_batch.size(0), -1)\n","    Y_pred = model(Xtr)\n","\n","    loss = criterion(Y_pred,Y_train_batch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    loss_train.append(loss.item())\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1_train.append( f1_score(Y_train_batch,Y_pred, average='macro') )\n","\n","    acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n","    acc_train.append(acc)\n","\n","    model.eval()\n","    Xvl = X_valid.view(X_valid.size(0), -1)\n","    Y_pred = model(Xvl)\n","    loss = criterion(Y_pred,Y_valid)\n","    loss_valid.append(loss.item())\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n","\n","    acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","    acc_valid.append(acc)\n","\n","    total_it += 1\n","\n","  print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch, loss_train[-1], f1_train[-1], acc_train[-1]) )"],"metadata":{"id":"DFe53ol4Ug28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(15,5))\n","plt.subplot(1,3,1)\n","plt.plot(range(total_it), loss_train, label='train')\n","# plt.plot(range(total_it), loss_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.grid()\n","plt.subplot(1,3,2)\n","plt.plot(range(total_it), f1_train, label='train')\n","plt.plot(range(total_it), f1_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('f1_score')\n","plt.legend()\n","plt.grid()\n","plt.subplot(1,3,3)\n","plt.plot(range(total_it), acc_train, label='train')\n","plt.plot(range(total_it), acc_valid, label='valid')\n","plt.xlabel('n_epoch')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.grid()"],"metadata":{"id":"TFEpX-JjUh4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #-- Evaluamos el modelo entrenado con el set de testeo\n","model.eval()\n","\n","Xts = X_test.view(X_test.size(0), -1)\n","Y_pred = model(Xts)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"],"metadata":{"id":"2ANZFvmUUjAL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exploración de Metaparámetros\n","\n","La exploración de metaparámetros consiste en la búsqueda de los valores óptimos de estos parámetros que me arrojan los mejores resultados (*loss*, *f1_score* y el *accuracy*), evitando los problemas en el cruze de subsets, underfitting y overfitting."],"metadata":{"id":"8lsYmhdxUm1W"}},{"cell_type":"markdown","source":["# Técnicas de Validación\n","\n","Las técnicas de validación consisten en la búsqueda de los metaparametros que mejor resultados nos retornan, las técnicas de validación comúnmente utilizadas son el **K-fold** y el **Grid search**.\n","\n","## K-fold\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg)\n","\n","\n","## Grid Search\n","\n","![](https://miro.medium.com/max/700/1*Xq9OvMKXhrF3W2RBJCWW7w.png)"],"metadata":{"id":"1b5rUc6WUosz"}},{"cell_type":"markdown","source":["# Ejercicio\n","\n","Utilizar la técnica de validación **Grid Search** para encontrar los parámetros óptimos que mejor permiten clasificar el dataset MNIST."],"metadata":{"id":"GjkrNF-bUqU5"}},{"cell_type":"markdown","source":["# Matriz de Confusión y F1 score\n","\n","![](https://lh5.googleusercontent.com/zQDulNDRB9PkFV-wzpw7WPQqSPSXAkRL_t8Pip0vA6Xy6egYQi4rYuh5VB6Bbh1hOAJ0IHy8CC9wDqy2AO_RfVCbxqXn2rUWupGfgJRv2dGrkaQJe5KRlqOw-61LvisAx2DHlnbk)\n","\n","![](https://static.packt-cdn.com/products/9781785282287/graphics/B04223_10_02.jpg)\n","\n","\n"],"metadata":{"id":"J6qIdzohUtYx"}},{"cell_type":"code","source":["#--- Definimos una función para calcular la matriz de confusión\n","\n","from sklearn.metrics import confusion_matrix\n","\n","def CM(Y_true, Y_pred, classes):\n","  fig = plt.figure(figsize=(10, 10))\n","  cm = confusion_matrix(Y_true, Y_pred)\n","  lclasses = np.arange(0,classes)\n","  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","  cmap=plt.cm.Blues\n","  ax = fig.add_subplot(1,1,1)\n","  im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","  ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.86)\n","  ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),xticklabels=lclasses, yticklabels=lclasses)\n","  ax.set_xlabel(\"Predicted\",size=20)\n","  ax.set_ylabel(\"True\",size=20)\n","  ax.set_ylim(classes-0.5, -0.5)\n","\n","  plt.setp(ax.get_xticklabels(), size=12)\n","  plt.setp(ax.get_yticklabels(), size=12)\n","\n","  fmt = '.2f'\n","  thresh = cm.max()/2.\n","  for i in range(cm.shape[0]):\n","      for j in range(cm.shape[1]):\n","          ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=15 , color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","  plt.show()"],"metadata":{"id":"TYt_pvwqUvxy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Metaparametros\n","\n","* **n_layers** = Número de capas\n","* **n_neurons** = Número de neuronas\n","* **n_epoch** = Número de épocas\n","* **lr** = Tasa de aprendizaje - learning rate\n","* **weight_decay** = peso de decaímiento\n","* **batch_size** = Tamaño del subconjunto"],"metadata":{"id":"tlRTU9DSUvbE"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","def train_valid(model, n_epoch, optimizer, criterion):\n","  loss_train = []\n","  f1_train = []\n","  acc_train = []\n","\n","  loss_valid = []\n","  f1_valid = []\n","  acc_valid = []\n","\n","  for epoch in range(n_epoch):\n","    model.train()\n","\n","    Xtr = X_train.view(X_train.size(0), -1)\n","    Y_pred = model(Xtr)\n","\n","    loss = criterion(Y_pred,Y_train)\n","    loss_train.append(loss.item())\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n","\n","    acc = sum(Y_train == Y_pred)/len(Y_pred)\n","    acc_train.append(acc)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    model.eval()\n","    Xvl = X_valid.view(X_valid.size(0), -1)\n","    Y_pred = model(Xvl)\n","    loss = criterion(Y_pred,Y_valid)\n","    loss_valid.append(loss.item())\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n","\n","    acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","    acc_valid.append(acc)\n","\n","  print( 'Valid Evaluation loss: {}. f1:{} acc: {} '.format(loss_valid[-1], f1_valid[-1], acc_valid[-1]) )\n","  CM(Y_valid, Y_pred, 10)"],"metadata":{"id":"atnL8gjMUyb-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset\n","from tqdm.notebook import tqdm\n","\n","\n","bs_list = [256,512,1024]\n","lr_list = [0.001,0.01,0.1]\n","wd_list = [0.001,0.01,0.1]\n","hd_list = [50,80,100]\n","ne_list = [50,100,150]\n","\n","pbar = tqdm(total=len(bs_list)*len(lr_list)*len(wd_list)*len(hd_list)*len(ne_list))\n","\n","for ne in ne_list:\n","  for bs in bs_list:\n","    train_ds = TensorDataset(X_train, Y_train)\n","    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n","\n","    for lr in lr_list:\n","      for wd in wd_list:\n","        for hd in hd_list:\n","          input_dim = 28*28\n","          out_dim = 10\n","          hidden = hd\n","\n","          model = torch.nn.Sequential(\n","            torch.nn.Linear(input_dim, hidden),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(hidden, out_dim)\n","          )\n","\n","          optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n","          criterion = torch.nn.CrossEntropyLoss()\n","\n","          print('ne: {}, hd:{}, wd:{}, lr: {}, bs:{} '.format(ne,hd,wd,lr,bs))\n","          train_valid(model,ne,optimizer,criterion)\n","          print('###################\\n')\n","\n","          pbar.update()\n","pbar.close()"],"metadata":{"id":"NhPA2r87Uzch"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Redes Neuronales Convolucionales\n","\n","Una red neuronal convolucional CNN es una de las ANN más comunes y usadas actualmente. Este tipo de red es una variación de un MLP, sin embargo, debido a que su aplicación es realizada en matrices bidimensionales, son muy efectivas para tareas de visión por computador, especificamente en tareas de clasificación y segmentación de imágenes.\n","\n","![](https://miro.medium.com/max/1200/1*3DUs-90altOgaBcVJ9LTGg.png)\n"],"metadata":{"id":"GbOzxZsYU33D"}},{"cell_type":"markdown","source":["# Capas de una CNN\n","\n","\n","#Capas Convolucionales\n","\n","A diferencia de las capas densamente conectadas (**Linear**) las redes convolucionales se componen principalmente de capas de convolución que reciben como parámetro de entrada el número de canales que componen el mapa bidimensional (en el caso de la primera capa convolucional es la imagen original). Para imágenes en escala de gris, en numero de canales es 1. En el caso de imágenes a color se podría trata de 3 (RGB) o 4 (RGBA) canales. La salida de una capa convolucional son un número de canales seleccionado. Cada canal tiene un mapa de características asociado y se obtiene al aplicar un kernel (filtro) sobre el mapa de entrada.\n","\n","## Kernel\n","**Ejemplo**:\n","\n","* *Input (x)*: 3x3\n","* *Kernel (w)*: 2x2\n","* *Output (z)*: 2x2\n","\n","El kernel hace una convolución por toda la imagen, de izquierda a derecha y de arriba a abajo, de modo que la salida es un mapa de características bidimensional donde en valor de cada entrada del mapa corresponde al producto $w*x$. Así por ejemplo, 0x0+ 1x1 + 2x3 + 4x3 = 19.\n","\n","![](https://classic.d2l.ai/_images/correlation.svg)\n","\n","Los kernel son definidos aleatoriamente por Pytorch, sin embargo, es posible pasarle un filtro específico para efectuar la convolución.\n","\n","## Padding\n","\n","De acuerdo al ejemplo de la imagen anterior al realizar la convolución, el tamaño del mapa de salida es menor que el tamaño del de entrada. Para evitar esta perdida de información en los bordes se puede utilizar el parametro *padding*. Este parámetro agrega información en los bordes, de modo que al pasar el kernel sobre todo el mapa, se recupera el tamaño inicial. El contenido de estos bordes extra depende del parámetro *padding_mode*, que toma por defecto el valor 'zeros'. En la imagen de ejemplo se aplica un padding igual a 1 y se utilizan ceros como valores por defecto. Más infromación [aquí](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n","\n","![](https://classic.d2l.ai/_images/conv-pad.svg)\n","\n","\n","## Stride\n","\n","Otro parámetro importante en la capa convolucional es el espacio entre cada aplicación del kernel, el kernel por defecto y luego de ejecutado, salta hacia la derecha un paso. Cuando termina horizontalmente, hace un salto vertical arrancando nuevamente desde la izquierda, así hasta barrer toda la imagen.\n","El valor de estos saltos horizontales y verticales se puede definir usando el parámetro *stride*. En la imagen de ejemplo se aplica un stride de la forma (2,3), dando como resultado una salida de tamaño 2x2.\n","\n","![](https://classic.d2l.ai/_images/conv-stride.svg)\n","\n","\n","# Max Pooling y Global Average Pooling\n","\n","La idea detrás de la técnica *Pooling* es perder resolución en la imagen para obtener las características más representativas de la imagen. El *max pooling* consiste en tomar el valor máximo de un kernel de *pooling* proyectáándolo en el mapa de salida. Una variedad de este método consiste en tomar el promedio global del kernel y no el máximo. El uso de técnicas de *pooling* se sustenta también en la disminución del número de características en la red.\n","\n","![](https://classic.d2l.ai/_images/pooling.svg)\n","\n","# Calculo del número de características\n","\n","Para calcular el tamaño de los mapas de características y el número total de característica de la red se usa la siguiente ecuación.\n","\n","$$\\large{ \\frac{W - F + 2P}{S} + 1 }$$\n","\n","Donde $W$ es el tamaño del ancho del mapa de características, $F$ el tamaño del kernel, $P$ el valor de padding y $S$ el valor del stride. De esta forma y utilizando la ecuación anterior en cada capa se puede controlar el tamaño de características en cada capa.\n","\n","_(Imágenes tomadas de: Dive into Deep Learning - Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola)_\n","\n","# Dropout\n","\n","Durante el entrenamiento es posible convertir algunos pesos en nulos, de modo que la red no aprenda las mismas conexiones en cada entrenamiento, si no que trate de encontrar diferentes caminos dentro de la red y así garantizar un aprendizaje más general.\n","\n","Esta es una técnica de regularización que previene la adaptación de las neuronas.\n","\n","\n","![](https://www.researchgate.net/publication/336754568/figure/fig3/AS:817383757328385@1571890882529/The-difference-between-standard-NN-and-Dropout-NN-53-Dropout-method-randomly-drops.ppm)"],"metadata":{"id":"dICBQFm3U6md"}},{"cell_type":"code","source":["#--- Definimos la CNN\n","\n","model = torch.nn.Sequential(\n","  torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n","  # ( (28-5+2*2)/1 ) + 1 = 28   -> 28*28*16\n","\n","  torch.nn.ReLU(),\n","\n","  torch.nn.MaxPool2d(kernel_size=2),\n","  # 28/2 = 14                 -> 14*14*16\n","\n","  torch.nn.Dropout(p=0.2),\n","\n","  torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","  # ( (14-5+2*2)/1 ) + 1 = 14   -> 14*14*32\n","\n","  torch.nn.ReLU(),\n","\n","  torch.nn.MaxPool2d(kernel_size=2),\n","  # 14/2 = 7                 -> 7*7*32\n","\n","  torch.nn.Dropout(p=0.2),\n","\n","  torch.nn.Flatten(),\n","  torch.nn.Linear(7*7*32, 10)\n",")\n","model"],"metadata":{"id":"JlJ1RfzxU7xd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Definimos los criterios de evaluación y el optmizador\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.1)"],"metadata":{"id":"-CHSt1F0VERj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install hiddenlayer"],"metadata":{"id":"lPTq6vVIVGAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Visualizamos la estructura de nuestra CNN\n","\n","import hiddenlayer as hl\n","\n","hl.build_graph(model, torch.zeros([32,1,28,28]))"],"metadata":{"id":"IPz2oFI2VG8q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Entrenamos la CNN\n","\n","from sklearn.metrics import f1_score\n","\n","n_epoch = 10\n","\n","history = hl.History()\n","canvas = hl.Canvas()\n","\n","iter = 0\n","\n","for epoch in range(n_epoch):\n","  for batch_id, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n","    model.train()\n","    #print(X_train_batch.size())\n","    Xtr = X_train_batch.unsqueeze(1)\n","    #print(Xtr.size())\n","    Y_pred = model(Xtr)\n","\n","    loss = criterion(Y_pred,Y_train_batch)\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","    f1 = f1_score(Y_train_batch, Y_pred, average='macro')\n","\n","    acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    iter += 1\n","\n","    if iter%10 == 0:\n","        #-- Visualizamos la evolución de los score loss y accuracy\n","        history.log((epoch+1, iter), loss=loss, accuracy=acc)\n","        with canvas:\n","          canvas.draw_plot(history[\"loss\"])\n","          canvas.draw_plot(history[\"accuracy\"])"],"metadata":{"id":"nsOwwxlfVIBW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualizando algunos mapas de características"],"metadata":{"id":"cX24Z53AVJ2O"}},{"cell_type":"code","source":["#-- Visualizando los mapas de características de la primera capa convolucional\n","kernels = list(model.children())[0].weight.detach()\n","\n","fig = plt.figure(figsize=(16,4))\n","k = 0\n","for i in range(kernels.size(0)):\n","    plt.subplot(2,8,k+1)\n","    plt.imshow(kernels[i].squeeze())\n","    k += 1\n","plt.show()"],"metadata":{"id":"PzO1hr0MVKrM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Evaluamos el modelo con nuestro set de validación\n","\n","model.eval()\n","Xvl = X_valid.unsqueeze(1)\n","Y_pred = model(Xvl)\n","loss = criterion(Y_pred,Y_valid)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_valid, Y_pred, average='macro')\n","\n","acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","\n","print( 'Loss:{:.2f}, F1:{:.2f}, Acc:{:.2f}'.format(loss.item(), f1, acc ) )"],"metadata":{"id":"Vtr6VHtWVMRq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Usando la GPU"],"metadata":{"id":"0makykPeVOBM"}},{"cell_type":"code","source":["#-- Después de activar el entorno GPU se selecciona el dispositivo\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"1WMzxGYpVPDm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Definimos el modelo\n","\n","model = torch.nn.Sequential(\n","  torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n","  #out: ( (28-5+2*2)/1 ) + 1 = 28   -> 28 x 28 x16\n","\n","  torch.nn.ReLU(),\n","\n","  torch.nn.MaxPool2d(kernel_size=2),\n","  #out: 28/2 = 14                 -> 14 x 14 x 16\n","\n","  torch.nn.Dropout(p=0.2),\n","\n","  torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","  #out: ( (14-5+2*2)/1 ) + 1 = 14   -> 14 x 14 x 32\n","\n","  torch.nn.ReLU(),\n","\n","  torch.nn.MaxPool2d(kernel_size=2),\n","  #out: 14/2 = 7                 -> 7 x 7 x 32\n","\n","  torch.nn.Dropout(p=0.2),\n","\n","  torch.nn.Flatten(),\n","  torch.nn.Linear(7*7*32, 10)\n",")\n","model"],"metadata":{"id":"U9YJpLefVYhA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#-- Cargamos el modelo en la GPU\n","model.to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.1)\n","\n","n_epoch = 10\n","\n","history2 = hl.History()\n","canvas2 = hl.Canvas()\n","\n","iter = 0\n","\n","for epoch in range(n_epoch):\n","  for batch_id, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n","\n","    #-- Cargamos los datos en la GPU\n","    X_train_batch, Y_train_batch = X_train_batch.to(device), Y_train_batch.to(device)\n","\n","    model.train()\n","    Xtr = X_train_batch.unsqueeze(1)\n","    Y_pred = model(Xtr)\n","\n","    loss = criterion(Y_pred,Y_train_batch)\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","\n","    #-- Calculamos el f1 en la cpu\n","    f1 = f1_score(Y_train_batch.cpu(),Y_pred.cpu(), average='macro')\n","\n","    acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    iter += 1\n","\n","    if iter%10 == 0:\n","        history2.log((epoch+1, iter), loss=loss, accuracy=acc)\n","        with canvas2:\n","          canvas2.draw_plot(history2[\"loss\"])\n","          canvas2.draw_plot(history2[\"accuracy\"])"],"metadata":{"id":"nbdVsUczVgR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Validamos el modelo\n","\n","X_valid, Y_valid = X_valid.to(device), Y_valid.to(device)\n","model.eval()\n","Xvl = X_valid.unsqueeze(1)\n","Y_pred = model(Xvl)\n","loss = criterion(Y_pred,Y_valid)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_valid.cpu(), Y_pred.cpu(), average='macro')\n","\n","acc = sum(Y_valid == Y_pred)/len(Y_pred)\n","\n","print( 'Loss:{:.2f}, F1:{:.2f}, Acc:{:.2f}'.format(loss.item(), f1, acc ) )"],"metadata":{"id":"63jFNGfbViw9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Lectura Recomendada\n","\n","[Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)"],"metadata":{"id":"UT3ET54nVlQN"}},{"cell_type":"markdown","source":["# Arquitecturas de algunas CNN\n","\n","Existe una variedad de arquitecturas de CNN que han sido diseñadas utilizando diferentes combinaciones de capas y algoritmos para la obtención de mejores resultados.\n","\n","La mayoría de estas CNN han probado su habilidad en datasets como COCO, Imagenet y CIFAR100, obteniendo muy buenos resultados.\n","\n","A continuación se mencinaran algunas de las CNN más conocidas.\n","\n","\n","# LeNet y AlexNet\n","\n","A la izquierda la estructura de LeNet (La primera CNN) y AlexNet su predecesora. AlexNet fue diseñada para abordar el reto del dataset **Imagenet**.\n","\n","![](https://d2l.ai/_images/alexnet.svg)"],"metadata":{"id":"9m9Rd6QOVoPW"}},{"cell_type":"code","source":["import torch\n","\n","model = torch.hub.load('pytorch/vision', 'alexnet', pretrained=True)\n","model"],"metadata":{"id":"MpnGczFsVlrn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list(model.children())[0][0]"],"metadata":{"id":"A_KDeED0VuNF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# De AlexNet a VGG\n","\n","![](https://d2l.ai/_images/vgg.svg)"],"metadata":{"id":"oHJS0AtwVxN1"}},{"cell_type":"code","source":["import torch\n","\n","model = torch.hub.load('pytorch/vision', 'vgg16', pretrained=True)\n","model"],"metadata":{"id":"Mka60F4YVz03"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# De VGG a NiN (Network in Network)\n","\n","![](https://d2l.ai/_images/nin.svg)"],"metadata":{"id":"F66F-9nQV1r8"}},{"cell_type":"markdown","source":["# Redes Residuales - ResNet\n","\n","![](https://d2l.ai/_images/resnet-block.svg)\n","\n","![](https://d2l.ai/_images/resnet18.svg)\n","\n","\n","_(Imágenes tomadas de: Dive into Deep Learning - Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola)_\n","\n","\n","\n","# Batch Normalization\n","\n","Batch normalization es un método que normaliza cada sub-set de datos (bath_size), como se mencionó inicialmente es necesario que los datos se normalicen para evitar que se tengan distancias muy diferentes entre ellos. En una imagen a color se pueden tener valores de 0 hasta 255. Normalizando los datos las distancias de los datos van de 0 a 1. Esto ayuda a la red neuronal a trabajar mejor. Cuando normalizamos los datos solo la capa de entrada se beneficia de esto, conforme los datos pasan por otras capas ocultas esta normalización se va perdiendo."],"metadata":{"id":"wt9PVr8mV3sL"}},{"cell_type":"code","source":["import torch\n","\n","model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n","model"],"metadata":{"id":"MFJxw7jvV5DN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Transferencia de Aprendizaje\n","\n","Una de las ventajas del DL es el uso de modelos preentrenados para resolver tareas nuevas, tareas para las cuales la ANN no fue entrenada inicialmente.\n","Esto es posible dado que en cada capa de la ANN se aprenden diferentes características con diferentes niveles de abstracción. La ANN se puede cortar en cualquier capa y utilizar los pesos aprendidos hasta esa capa. A la capa cortada se le pueden anexar nuevas capas. Posteriormente se entrena el modelo con los nuevos datos. Este entrenamiento es más rápido pues inicia desde un punto avanzado y no desde cero. Esta técnica se conoce como transferencia de aprendizaje (**transfer learning**).\n","\n","![](https://drive.google.com/uc?id=1GehRE6XF75ufwlyRAP5YmrDY2gV839rq)\n","Sebastian Ruder, \"Transfer Learning - Machine Learning's Next Frontier\". http://ruder.io/transfer-learning/, 2017.\n","\n","<br>\n","\n","El *Transfer Learning* es un método de optimización, un atajo para ahorrar tiempo y obtener mejores resultados, pues se suelen utilizar modelos entrenados con grandes datasets, que continen alta cantidad de clases y variabilidad de datos.\n","\n","<br>\n","\n","Este método tiene tres grandes ventajas:\n","\n","* **Inicio avanzado**. La capacidad inicial en el modelo de origen (antes de refinar el modelo) es mayor de lo que sería iniciando desde cero.\n","* **Pendiente más alta**. La tasa de precisión durante el entrenamiento del modelo es más pronunciada.\n","* **Asíntota superior**. La tasa de convergencia del modelo entrenado es mejor.\n"],"metadata":{"id":"KwYKCwtFWBb1"}},{"cell_type":"markdown","source":["# Cargando un modelo pre-entrenado\n","\n","Para nuestro ejercicio usaremos ResNet18, una red Red Neuronal Convolucional con 18 capas de profundidad. Recordemos que el nombre de **Residual-Net** proviene de la estrategia de usar conexiones de salto residualmente dentro de bloques (llamados bloques residuales, ver Figura), donde la entrada *x* se agrega directamente a la salida del bloque, es decir, *F(x) + x* garantizando el aumento en la profundidad de la red al omitir ciertas capas utilizando conexiones de omisión o bloques residuales. Un gran avance para el problema de optimización/degradación con redes profundas.\n","[Paper de presentación de ResNet](https://arxiv.org/pdf/1512.03385.pdf).\n","\n","![](https://drive.google.com/uc?id=1L4pWbh0zANQQz-8oLruKhwmyITm2UWdK)\n","\n","<br>\n","\n","El modelo pre-entrenado puede clasificar imágenes en al menos 1000 categorías diferentes, tal como teclado, mouse, lápiz y diferentes clases de animales. Dada la variedad de objetos en el dataset de entrenamieto el modelo es rico en representación de features en un alto rango de clases. ResNet fue entrenado con [Imagenet](https://image-net.org/) un gigantesco dataset visual diseñado para el uso de proyectos en reconocimiento de objetos. Imagenet tiene al menos 14 millones de imágenes anotadas. La entrada de la red tiene un tamaño de 224x224x3.\n","\n"],"metadata":{"id":"np3mtCnEWD0s"}},{"cell_type":"markdown","source":["Al momento de cargar los datos es necesario reescalarlos al tamaño de entrada del modelo reciclado en este caso (224,224,3). Es necesario reescalar y normalizar las imágenes (La normalización se hace usando la media y la desviación estándar). La normalización ayuda a la red a converger más rápido."],"metadata":{"id":"aC8_xlEqWGpO"}},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","\n","#--- Transformamos los datos para adaptarlos a la entrada de ResNet 224x224 px\n","data_transform = transforms.Compose([\n","                 transforms.Resize((224, 224)),\n","                 transforms.Grayscale(3), #Dado que MNIST tiene un solo canal, lo cambiamos a 3 para no tener que modificar más capas en el modelo\n","                 transforms.ToTensor(),\n","                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n","                 ])"],"metadata":{"id":"6V27ZLhHWIbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Cargamos los datos de entrenamiento en listas\n","from PIL import Image\n","\n","N_train = len(train_files)\n","X_train = []\n","Y_train = []\n","\n","for i, train_file in enumerate(train_files):\n","  Y_train.append( int(train_file.split('/')[3]) )\n","  X_train.append( np.array(data_transform(Image.open(train_file) )))"],"metadata":{"id":"8xII7WRKWLAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Cargamos los datos de testeo en listas\n","N_test = len(test_files)\n","X_test = []\n","Y_test = []\n","\n","for i, test_file in enumerate(test_files):\n","  Y_test.append( int(test_file.split('/')[3]) )\n","  X_test.append( np.array(data_transform(Image.open(test_file)) ))"],"metadata":{"id":"usyW0DRkWMIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Visualizamos los datos\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure(figsize=(8,8))\n","for i in range(4):\n","  plt.subplot(2,2,i+1)\n","  plt.imshow(X_test[i*15].reshape(224,224,3))\n","  plt.title(Y_test[i*15])\n","  plt.axis(False)\n","plt.show()"],"metadata":{"id":"7ccDQnV6WMBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Convetimos las listas con los datos a tensores de torch\n","import torch\n","from torch.autograd import Variable\n","\n","X_train = Variable(torch.from_numpy(np.array(X_train))).float()\n","Y_train = Variable(torch.from_numpy(np.array(Y_train))).long()\n","\n","X_test = Variable(torch.from_numpy(np.array(X_test))).float()\n","Y_test = Variable(torch.from_numpy(np.array(Y_test))).long()\n","\n","X_train.data.size()"],"metadata":{"id":"eJBen8hBWO3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Creamos el DataLoader\n","\n","batch_size = 32\n","\n","train_ds = torch.utils.data.TensorDataset(X_train, Y_train)\n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"CptnkefVWP2d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Entrenando el modelo"],"metadata":{"id":"7N58WyTmWRUV"}},{"cell_type":"code","source":["#--- Seleccionamos y cargamos el modelo\n","import torch\n","\n","model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n","model"],"metadata":{"id":"aH0o75qWWS3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Congelamos los pesos en las capas del modelo para que no se actualicen\n","for p in model.parameters():\n","    p.requires_grad = False\n","\n","#--- Definimos el número de clases\n","out_dim = 10\n","\n","#--- Reescribimos la nueva capa de salida con el nuevo dataset\n","model.fc = torch.nn.Sequential(\n","  torch.nn.Linear(model.fc.in_features, out_dim)\n",")\n","\n","model.load_state_dict(model.state_dict())\n","\n","model"],"metadata":{"id":"dZJPYYQnWUJh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install hiddenlayer"],"metadata":{"id":"_PGsqRYMWWPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Visualizamos la estructura de nuestra CNN\n","\n","import hiddenlayer as hl\n","\n","hl.build_graph(model, torch.zeros([64,3,264,264]))"],"metadata":{"id":"pTxyf075WXEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Creamos variables para almacenar los scores en cada época\n","\n","model = model.cuda()\n","\n","model.train()\n","\n","#--- Definimos nuestro criterio de evaluación y el optimizador\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.1)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","\n","#--- Entrenamos el modelo usando únicamente 5 épocas\n","n_epochs = 5\n","\n","history = hl.History()\n","canvas = hl.Canvas()\n","\n","iter = 0\n","\n","for epoch in range(n_epochs):\n","  for batch_idx, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n","    # Pasamos os datos a 'cuda'\n","\n","    # X_train_batch = X_train_batch.cuda()\n","    # Y_train_batch = Y_train_batch.cuda()\n","\n","    # Realiza una predicción\n","    Y_pred = model(X_train_batch)\n","\n","    # Calcula el loss\n","    loss = criterion(Y_pred, Y_train_batch)\n","\n","    Y_pred = torch.argmax(Y_pred, 1)\n","\n","    # Calcula el accuracy\n","    acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n","\n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if iter%10 == 0:\n","        #-- Visualizamos la evolución de los score loss y accuracy\n","        history.log((epoch+1, iter), loss=loss, accuracy=acc)\n","        with canvas:\n","          canvas.draw_plot(history[\"loss\"])\n","          canvas.draw_plot(history[\"accuracy\"])\n","\n","    iter += 1\n","    del X_train_batch, Y_train_batch, Y_pred"],"metadata":{"id":"yKu1I8BlWYeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Validamos el modelo\n","from sklearn.metrics import f1_score\n","\n","# model.cpu()\n","model.eval()\n","\n","Y_pred = model(X_test)\n","loss = criterion(Y_pred,Y_test)\n","\n","Y_pred = torch.argmax(Y_pred, 1)\n","f1 = f1_score(Y_test, Y_pred, average='macro')\n","\n","acc = sum(Y_test == Y_pred)/len(Y_pred)\n","\n","print( 'Loss:{:.2f}, F1:{:.2f}, Acc:{:.2f}'.format(loss.item(), f1, acc ) )"],"metadata":{"id":"4nxT548BWYYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--- Guardamos el nuevo Modelo\n","torch.save(model,open('./ResNet_MNIST.pt','wb'))"],"metadata":{"id":"Z_HVm0tXWbH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","def CM(Y_true, Y_pred, classes, lclasses=None):\n","  fig = plt.figure(figsize=(10, 10))\n","  cm = confusion_matrix(Y_true, Y_pred)\n","  if lclasses == None:\n","    lclasses = np.arange(0,classes)\n","  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","  cmap=plt.cm.Blues\n","  ax = fig.add_subplot(1,1,1)\n","  im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","  ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.86)\n","  ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),xticklabels=lclasses, yticklabels=lclasses)\n","  ax.set_xlabel(\"Predicted\",size=20)\n","  ax.set_ylabel(\"True\",size=20)\n","  ax.set_ylim(classes-0.5, -0.5)\n","\n","  plt.setp(ax.get_xticklabels(), size=12)\n","  plt.setp(ax.get_yticklabels(), size=12)\n","\n","  fmt = '.2f'\n","  thresh = cm.max()/2.\n","  for i in range(cm.shape[0]):\n","      for j in range(cm.shape[1]):\n","          ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=15 , color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","  plt.show()"],"metadata":{"id":"ukeioQ19Wcxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CM(Y_test, Y_pred, 10)"],"metadata":{"id":"7evhuMFQWeEX"},"execution_count":null,"outputs":[]}]}