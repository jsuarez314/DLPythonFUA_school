{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqRoN9POHLig"
   },
   "source": [
    "# MÓDULO 7.  Introducción a Deep Learning  (8 horas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6FTXu7mParm"
   },
   "source": [
    "## **7.1 Introducción al Deep Learning**\n",
    "\n",
    "El aprendizaje profundo, también conocido como Deep Learning (DL) en inglés, ha experimentado un notorio auge en la última década, consolidándose como un subconjunto destacado dentro de las técnicas de Machine Learning (ML). Este último, a su vez, se sitúa como un componente esencial en el amplio campo de la Inteligencia Artificial, Artificial Intelligence (AI), en inglés. El DL se distingue por su capacidad para procesar y aprender automáticamente a partir de datos, utilizando arquitecturas de redes neuronales profundas, Deep Neural Networks (DNN). Este enfoque ha permitido avances significativos en tareas complejas como el reconocimiento de imágenes, procesamiento del lenguaje natural y la toma de decisiones autónomas en diversas aplicaciones. En este contexto, la intersección entre el DL, el ML y la AI continúa desempeñando un papel crucial en la evolución y aplicación de tecnologías innovadoras.\n",
    "\n",
    "<center><img src=\"./img/ai_ml_dl.jpeg\"></center>\n",
    "\n",
    "**Fuente: AI & Machine Learning: The evolution, differences and connections - Kapil Tandon**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdNOsVxiPc7L"
   },
   "source": [
    "### **7.2 Inteligencia Artificial**\n",
    "\n",
    "La Inteligencia Artificial (IA) representa una fascinante rama de investigación en el ámbito de las ciencias computacionales (Computer Science). Su objetivo principal radica en emular la capacidad humana de adquirir información, analizar datos y tomar decisiones.\n",
    "\n",
    "<center><img src=\"./img/ai.png\"></center>\n",
    "\n",
    "**Inicios**\n",
    "\n",
    "El surgimiento de la IA se remonta a finales de la década de 1950, cuando surgió como un desafío inicial: programar computadoras para realizar tareas que los humanos ejecutan con facilidad pero que las máquinas no habían logrado realizar hasta ese momento.\n",
    "\n",
    "En 1950, Allan Turing dejó una marca indeleble en el campo de la inteligencia artificial con su artículo Computing Machinery and Intelligence, donde propuso una prueba específica para determinar la inteligencia de una máquina. La famosa Prueba de Turing evalúa si un resultado proviene de una máquina o de un ser humano. Gracias a sus contribuciones, Turing es considerado el padre de la IA.\n",
    "\n",
    "**Estado del Arte**\n",
    "\n",
    "Desde sus inicios, la IA ha avanzado enormemente en la consecución de su objetivo original: simular las capacidades humanas. Ha logrado realizar tareas desafiantes y generar soluciones repetitivas. No obstante, los avances en este campo han sido colosales. La IA ha permeado distintos aspectos de nuestra vida cotidiana de manera tan natural que a veces ni siquiera nos percatamos de que estamos utilizando tecnologías basadas en este principio.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Algunos Ejemplos**\n",
    "\n",
    "  1) Aplicaciones Diarias\n",
    "\n",
    "  * Clasificación de Spam en los emails\n",
    "\n",
    "  <center><img src=\"./img/spam.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "  * Sugerencias de Netflix\n",
    "  \n",
    "  <center><img src=\"./img/netflix.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "2) Aplicaciones en Ciencia\n",
    "\n",
    "  * Búsqueda eficiente de candidatos a medicamentos.\n",
    "  \n",
    "  <center><img src=\"./img/drugs.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "  * Segmentación de elementos quirúrgicos - [CinfonIA](https://cinfonia.uniandes.edu.co/)\n",
    "  \n",
    "  <center><img src=\"./img/segment.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "3) Aplicaciones en Ilustración y Arte\n",
    "\n",
    "  * Copiando estilos\n",
    "\n",
    "  <center><img src=\"./img/style.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "  * Diseño de Fondos (NVIDIA) - [GauGAN](http://nvidia-research-mingyuliu.com/gaugan/)\n",
    "\n",
    "  <center><img src=\"./img/gaugan.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "  * Creación Artificial de Rostros - [This person does not exists](https://thispersondoesnotexist.com/)\n",
    "\n",
    "  <center><img src=\"./img/tpdne.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVKy3IsNPp3b"
   },
   "source": [
    "### **7.3 Aprendizaje Automático**\n",
    "\n",
    "Un hito clave en la historia de la IA fue el surgimiento del Machine Learning (ML), un conjunto de algoritmos diseñados para construir modelos de aprendizaje entrenados, validados y probados con datos previamente procesados. Este modelo, resultado del ciclo de entrenamiento-validación-testeo, se emplea posteriormente con nuevos datos para realizar predicciones o tomar decisiones basadas en la tarea específica para la cual fue diseñado.\n",
    "\n",
    "Durante la etapa de entrenamiento, el modelo aprende las características de un conjunto de datos denominado \"datos de entrenamiento\". Posteriormente, se mejora el modelo mediante un conjunto de \"datos de validación\", ajustando los parámetros del algoritmo, y finalmente, se evalúa con \"datos de testeo\" utilizando los parámetros que ofrecieron los mejores resultados. Estos tres conjuntos de datos son completamente diferentes, asegurando que el algoritmo no repite el aprendizaje de los datos de entrenamiento, sino que realmente puede extrapolar resultados para datos nuevos.\n",
    "\n",
    "Existen dos mecanismos principales de ML:\n",
    "\n",
    "**Supervisado:**\n",
    "\n",
    "Este enfoque implica algoritmos donde los datos están etiquetados, es decir, cada dato tiene una etiqueta que lo caracteriza. Esta etiqueta puede representar una clase (manzana, limón, tomate) o un valor numérico. El objetivo del algoritmo es predecir la etiqueta que mejor describe un objeto en función de sus características. Comúnmente, estos algoritmos realizan tareas de regresión o clasificación.\n",
    "\n",
    "<center><img src=\"./img/supervised.png\"></center>\n",
    "    \n",
    "**No Supervisado**\n",
    "\n",
    "A diferencia del enfoque supervisado, en el mecanismo no supervisado, el algoritmo desconoce las etiquetas de los datos y utiliza únicamente las características para identificar patrones. Este tipo de algoritmos se utilizan comúnmente para visualizar grandes volúmenes de datos con alta dimensionalidad en espacios reducidos (reducción de dimensionalidad) e identificar agrupamientos de datos (clustering).\n",
    "\n",
    "<center><img src=\"./img/unsupervised.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ougVPLZ0PtEL"
   },
   "source": [
    "### **7.4 Aprendizaje Profundo**\n",
    "\n",
    "El Aprendizaje Profundo (Deep Learning, DL) se configura como un conjunto de algoritmos de aprendizaje automático (ML) fundamentados en redes neuronales, las cuales utilizan progresivamente múltiples capas con la capacidad de extraer representaciones desde niveles bajos hasta altos mediante la manipulación de datos en bruto.\n",
    "\n",
    "La siguiente imagen ilustra de manera clara un ejemplo de extracción de características. Mientras las primeras capas del algoritmo extraen patrones simples, como diagonales, horizontales o círculos, las capas más profundas pueden identificar conceptos más complejos y relevantes para un observador humano, como partes específicas de una cara.\n",
    "\n",
    "<center><img src=\"./img/dl_face.png\"></center>\n",
    "\n",
    "Existen diversas estructuras de Redes Neuronales, cada una diseñada para tareas específicas, entre ellas:\n",
    "\n",
    "    1. Deep neural networks\n",
    "    2. Deep belief networks\n",
    "    3. Deep reinforcement learning\n",
    "    4. Recurrent neural networks\n",
    "    5. Convolutional neural networks\n",
    "    6. Transformers\n",
    "\n",
    "Al igual que los algoritmos de ML, los métodos de DL se emplean en tareas de regresión y clasificación, así como también en reducción de dimensionalidad y clustering.\n",
    "\n",
    "**Transferencia de Aprendizaje**\n",
    "\n",
    "A diferencia de los algoritmos de ML, los de DL permiten la reutilización para nuevas tareas. Dado que los modelos de DL aprenden features a diferentes niveles en cada capa, la información contenida en cada capa (pesos o weights) puede transferirse para resolver problemas nuevos sin necesidad de un entrenamiento desde cero. Esta técnica se conoce como Transfer Learning.\n",
    "\n",
    "**Redes Adversariales Generativas (GANs)**\n",
    "\n",
    "Una aplicación fascinante en Aprendizaje Profundo son las Redes Adversariales Generativas (GANs - Generative Adversarial Networks), un par de redes que compiten entre sí para generar datos nuevos que se asemejen a los reales. Mientras una red genera datos, la otra red evalúa la calidad del dato generado. El objetivo es que la red generadora produzca datos tan similares a los reales que la red discriminadora los considere auténticos.\n",
    "\n",
    "**Transformers**\n",
    "\n",
    "Una innovación destacada en el ámbito del Aprendizaje Profundo son los modelos basados en Transformers. Estos modelos han revolucionado diversas áreas del procesamiento del lenguaje natural y más allá, al superar limitaciones de las arquitecturas anteriores.\n",
    "\n",
    "La arquitectura Transformer, introducida en el artículo \"Attention is All You Need\" por Vaswani et al., se destaca por su mecanismo de atención, que permite a los modelos procesar secuencias de manera paralela y capturar relaciones de largo alcance. Este enfoque ha demostrado ser altamente eficaz en tareas como la traducción automática, la generación de texto y la comprensión del lenguaje.\n",
    "\n",
    "La principal ventaja de los Transformers radica en su capacidad para manejar secuencias de longitud variable y capturar patrones complejos en datos secuenciales. Su arquitectura ha sido la base de modelos preentrenados, como BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pretrained Transformer) y otros, que han establecido nuevos estándares en tareas de procesamiento del lenguaje natural.\n",
    "\n",
    "Los Transformers también se han extendido a otras áreas más allá del procesamiento del lenguaje natural, aplicándose con éxito en tareas de visión por computadora y otros dominios, consolidándose como una herramienta versátil en el arsenal de técnicas de aprendizaje profundo.\n",
    "\n",
    "\n",
    "**Algunos Ejemplos**\n",
    "\n",
    "El Aprendizaje Profundo abarca una amplia variedad de aplicaciones, destacándose en campos como la visión por computadora (CV), el reconocimiento de voz (SR), el procesamiento del lenguaje natural (NLP), la traducción automática (MT), bioinformática, diseño de fármacos y análisis de imágenes médicas. Los resultados obtenidos mediante Aprendizaje Profundo son comparables e incluso superan los logrados por expertos humanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ048DU6Q7aP"
   },
   "source": [
    "## **7.2 Redes Neuronales Artificiales**\n",
    "\n",
    "### **7.21. Importancia de las Redes Neuronales**\n",
    "\n",
    "El desarrollo de las Redes Neuronales Artificiales (Artificial Neural Networks, ANN) marcó un paso gigantesco en la resolución de diversas tareas basadas en algoritmos. Aunque los primeros artículos que describían el comportamiento de las ANN datan de la década de los 70, no fue hasta 40 años después que la tecnología que las sustentaría se desarrolló completamente. Además del aumento en la capacidad computacional y las mejoras en el cálculo en paralelo, las ANN se han beneficiado enormemente de la recopilación masiva de datos. Algunos conjuntos de datos basados en imágenes, como CIFAR100, COCO o Imagenet, han sido fundamentales en este avance.\n",
    "\n",
    "<center><img src=\"./img/coco-logo.png\"></center>\n",
    "<center><img src=\"./img/imagenet-logo.jpg\"></center>\n",
    "\n",
    "Esta combinación de factores ha propiciado el rápido avance de las ANN, convirtiéndolas en herramientas esenciales para el estudio, la investigación y el desarrollo. La potencia de las ANN se ha demostrado en una amplia gama de aplicaciones, que van desde tareas de reconocimiento de imágenes hasta el descubrimiento de nuevos medicamentos. Las ANN se han convertido en un componente transversal de las ciencias, tanto sociales como naturales.\n",
    "\n",
    "Una de las grandes ventajas de las ANN es su capacidad para analizar diversas fuentes de datos, desde texto (en una rama conocida como procesamiento de lenguaje natural - NLP) hasta imágenes y contenido visual enriquecido (video) (en una rama llamada visión por computadora - CV).\n",
    "\n",
    "### **7.2.2 ¿Qué es una Red Neuronal?**\n",
    "\n",
    "#### **7.2.2.1 Unidad Neuronal**\n",
    "\n",
    "Las Redes Neuronales Artificiales constituyen el núcleo del DL. La primera red neuronal se inspiró en el funcionamiento de las neuronas biológicas. La unidad fundamental en ambas, la red neuronal biológica y la artificial, es la neurona. Aunque la comparación suele ser superficial, una manera más efectiva de entender una neurona es visualizarla como una función matemática, donde una entrada produce una salida. La siguiente figura presenta una comparación simple entre una neurona biológica y una neurona artificial (perceptrón).\n",
    "\n",
    "<center><img src=\"./img/neuron.png\"></center>\n",
    "**From: Similarity between biological and artificial neural networks (Arbib, 2003a; Haykin, 2009b).**\n",
    "\n",
    "<br>\n",
    "\n",
    "**El Perceptrón**\n",
    "\n",
    "El perceptrón está compuesto por diferentes elementos en dos zonas de transformación. El *input* consiste en los datos recibidos por el perceptrón. Cada dato se pondera por un peso (*weight*) $w_{n}$. Los productos entre las entradas $x$ y los pesos $w$ se suman linealmente junto a un valor constante llamado *bias*, así $z = \\Sigma x_n w_{n} + b$ (Transformación lineal). El resultado pasa por una función no lineal, conocida como función de activación, que se activará o no dependiendo del valor de la suma, generando una salida *out* (Transformación no lineal).\n",
    "\n",
    "Esta activación nos indica si la salida coincide con la esperada, y para determinarlo, calculamos un error, definido como la diferencia entre lo esperado y lo obtenido, $\\Delta = y - \\bar{y}$. Este error se utiliza para actualizar los pesos. Cada vez que se obtiene una salida del perceptrón, se dice que ha ocurrido una época. Después de cada época, los pesos se actualizan así: $w_n = w_n + \\eta*\\Delta*x_n$, donde $\\eta$ es un parámetro conocido como la tasa de aprendizaje (learning rate).\n",
    "\n",
    "<center><img src=\"./img/perceptron.png\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_50jkWZuRAi4"
   },
   "source": [
    "##### **Ejercicio:** Perceptron\n",
    "\n",
    "A continuación de desarrolla un código en Python que describe el comportamiento de un Perceptron, el modelo más sencillo de una neurona y base de las NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fysWS1l8RBxv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/percep_linear.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0F7_OHDRDF2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = data['X1']\n",
    "x2 = data['X2']\n",
    "Y = data['Y']\n",
    "\n",
    "class_0 = Y == 0 # Esto es una máscara\n",
    "class_1 = Y == 1 # Esto es una máscara\n",
    "\n",
    "#-- Graficamos los puntos con sus correspondientes clases\n",
    "fig = pl.figure(figsize=(4,4))\n",
    "pl.plot(x1[class_0],x2[class_0],'o', c='black', label='0')\n",
    "pl.plot(x1[class_1],x2[class_1],'o', c='red', label='1')\n",
    "pl.xlim(0,1)\n",
    "pl.ylim(0,1)\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbDG59ILRJZG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Definimos nuestra función de activación, en este caso usamos un Sigmoide\n",
    "def act(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "402CPvKmRMEd"
   },
   "source": [
    "Otros ejemplos de funciones de activación...\n",
    "\n",
    "<center><img src=\"./img/activation.png\"></center>\n",
    "\n",
    "<center><img src=\"./img/activation2.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2_ZV3aeRNsu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Definimos el Perceptron\n",
    "\n",
    "# Inicializamos los pesos en 0\n",
    "b = 0\n",
    "w_1 = 0\n",
    "w_2 = 0\n",
    "\n",
    "# Inicializamos el número de épocas y la rata de aprendizaje\n",
    "n_epochs = 15 # Número de épocas\n",
    "n = 0.5      # Tasa de aprendizaje\n",
    "\n",
    "# Esta es la función nuestro perceptron encontrará al final de todas las épocas\n",
    "def y(x):\n",
    "    return -(b + w_1*x)/w_2\n",
    "\n",
    "# Entrenamos el Perceptron\n",
    "for epoch in range(n_epochs):\n",
    "    for i,j,k in zip(x1,x2,Y):\n",
    "        \n",
    "        # Función de Suma\n",
    "        z = i*w_1 + j*w_2 + b\n",
    "\n",
    "        # Función de Activación\n",
    "        sig_z = act(z)\n",
    "\n",
    "        # Evaluamos la salida (output)\n",
    "        if sig_z >= 0.5:\n",
    "            out = 1\n",
    "        if sig_z < 0.5:\n",
    "            out = 0\n",
    "\n",
    "        # Calculamos el error\n",
    "        error = k - out\n",
    "\n",
    "        # Actualizamos los pesos\n",
    "        b = b + n*error\n",
    "        w_1 += n*error*i\n",
    "        w_2 += n*error*j\n",
    "\n",
    "        print('Epoch [{}/{}], bias: {}, w1: {}, w2: {}'.format(epoch+1,n_epochs,b,w_1,w_2))\n",
    "\n",
    "        fig = pl.figure(figsize=(4,4))\n",
    "        pl.plot(x1[class_0],x2[class_0],'o', c='black', label='0')\n",
    "        pl.plot(x1[class_1],x2[class_1],'o', c='red', label='1')\n",
    "        pl.plot(np.sort(x1),y(np.sort(x1)),'-', c='green',)\n",
    "        pl.xlim(0,1)\n",
    "        pl.ylim(0,1)\n",
    "        pl.legend()\n",
    "        pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVk9liw8QHV-"
   },
   "source": [
    "#### 7.2.2.2 **Perceptron de Multiples Capas - MLP**\n",
    "\n",
    "Los perceptrones multicapa son un tipo de Red Neuronal Artificial (ANN) formado por múltiples capas de neuronas, lo que les confiere la capacidad de resolver problemas que no son linealmente separables, superando así la principal limitación del perceptrón.\n",
    "\n",
    "Los perceptrones de múltiples capas son conjuntos de perceptrones conectados, donde la salida de un perceptrón en una capa actúa como entrada para una neurona en la siguiente capa. Esta estructura permite extraer representaciones más complejas y detalladas de la información que ingresa a la ANN.\n",
    "\n",
    "En este tipo de red, los datos de entrada atraviesan varias capas de neuronas, conocidas como capas ocultas. La salida de estas capas ocultas se convierte en la entrada para una neurona de salida, de la cual obtenemos un único resultado. La siguiente figura esquematiza cómo la información fluye a través de cada neurona en las diferentes capas.\n",
    "\n",
    "<center><img src=\"./img/ann.png\"></center>\n",
    "\n",
    "De manera similar a cómo un perceptrón actualiza sus pesos, los perceptrones multicapa actualizan los pesos de todas sus neuronas en un proceso denominado backpropagation (o retropropagación). Este proceso es realizado por el optimizador, que calcula el gradiente de la función de error para cada peso de la red. Estos pesos se actualizan en cada época, y el objetivo es minimizar el error.\n",
    "\n",
    "<center><img src=\"./img/backpropagation.png\"></center>\n",
    "\n",
    "Las ANN modernas utilizan una combinación de múltiples capas y se conocen como redes neuronales profundas (**Deep Neural Networks**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxg1dAutQKcN"
   },
   "source": [
    "##### **Ejercicio:** Percetron Multicapas\n",
    "\n",
    "En este ejercicio usaremos el dataset de [red wine quality](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) para clasificar el vino entre vino de alta calidad y vino de baja calidad usando todos los *features* del dataset. El modelo que usaremos será un [Multi Layer Perceptron Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) del paquete [scikitlearn](https://scikit-learn.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "executionInfo": {
     "elapsed": 994,
     "status": "error",
     "timestamp": 1698026282400,
     "user": {
      "displayName": "JOHN FREDY SUAREZ PEREZ",
      "userId": "07610715876772400534"
     },
     "user_tz": 300
    },
    "id": "GZC4Hn2xG2zt",
    "outputId": "7495e8e9-4483-42db-d7ec-23652aa92a39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Leemos los datos con pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/winequality-red.csv')\n",
    "\n",
    "#-- Identificamos los nombres de las columnas\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1698026282403,
     "user": {
      "displayName": "JOHN FREDY SUAREZ PEREZ",
      "userId": "07610715876772400534"
     },
     "user_tz": 300
    },
    "id": "dg1nLG7aQMbY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Cargamos los features y los objetivos\n",
    "\n",
    "X = data.drop(['quality'], axis = 'columns')\n",
    "Y = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "error",
     "timestamp": 1698026286624,
     "user": {
      "displayName": "JOHN FREDY SUAREZ PEREZ",
      "userId": "07610715876772400534"
     },
     "user_tz": 300
    },
    "id": "pLJMxMNvQNXf",
    "outputId": "2c0df5c4-2ad8-4fab-9eb3-90bf7271a71a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Visualizamos los objetivos en un histograma\n",
    "import pylab as pl\n",
    "\n",
    "fig = pl.figure(figsize=(5,5))\n",
    "pl.hist(Y)\n",
    "pl.ylabel('Counts')\n",
    "pl.xlabel('quality')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3i6wA0qQOvH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Convertimos nuestro objetivo en un problema binario\n",
    "import numpy as np\n",
    "Y = np.array(Y)\n",
    "\n",
    "Y[Y<6] = 0\n",
    "Y[Y>=6] = 1\n",
    "\n",
    "fig = pl.figure(figsize=(5,5))\n",
    "pl.hist(Y)\n",
    "pl.ylabel('Counts')\n",
    "pl.xlabel('quality')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSmXe2C7QQ49",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Dividimos nuestro dataset en Train/Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFv6tntMQRtu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cargamos MLPCLassifier para buscar un modelo\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(activation='relu',  hidden_layer_sizes=(2, 2), solver='adam', learning_rate_init=0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eh3fY98QStP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Entrenamos el modelo y realizamos una predicción\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBXD2oPEQTuO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moHqFprKQVFp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Evaluamos el modelo con el accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u43BfWStQXS3"
   },
   "source": [
    "### 7.2.2.3 Arquitectura de una Red Neuronal\n",
    "\n",
    "En resumen, la arquitectura de una ANN está definida por el número y la forma de sus capas. En el estado del arte de estas ANN esas arquitecturas suelen ser un poco complejas, con algunas capas saltando sobre otras capas o capas que retornan información de regreso a capas anteriores.\n",
    "\n",
    "En el siguiente veremos un ejemplo sencillo de una red neuronal, para entender cuál es la función de cada una de las capas que la componen. Para diseñar esta red neuronal usaremos el framework [PyTorch](https://pytorch.org/) y el dataset estándar para la clasificación de tres especies de flores [IRIS](https://archive.ics.uci.edu/ml/datasets/Iris)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UuH2M2xQf9Y"
   },
   "source": [
    "##### **Ejercicio:** Red Neuronal con Pytorch\n",
    "\n",
    "En este ejercicio construiremos una red neuronal sencilla para hacer un ejercicio de clasificación usando el dataset [IRIS](https://archive.ics.uci.edu/ml/datasets/Iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VB2IUwPDQk-u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlsWpbGsQm_i",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Extraemos la infromación más importante\n",
    "X = iris['data']\n",
    "Y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "#-- Normalizamos los datos para que tengan media 0 y desviación 1\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#-- Dividimos los datos entre un conjunto de entrenamiento y testeo\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#-- Visualizamos el tamaño de los datos de entrenamiento\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvsez6I7QpA5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--Visualizamos los datos\n",
    "class0 = Y == 0\n",
    "class1 = Y == 1\n",
    "class2 = Y == 2\n",
    "\n",
    "\n",
    "fig = pl.figure(figsize=(10,5))\n",
    "pl.subplot(1,2,1)\n",
    "pl.plot(X_scaled[:,0][class0],X_scaled[:,1][class0],'o',c='red', label=names[0])\n",
    "pl.plot(X_scaled[:,0][class1],X_scaled[:,1][class1],'o',c='blue', label=names[1])\n",
    "pl.plot(X_scaled[:,0][class2],X_scaled[:,1][class2],'o',c='green', label=names[2])\n",
    "pl.grid()\n",
    "pl.legend()\n",
    "pl.xlabel(feature_names[0])\n",
    "pl.ylabel(feature_names[1])\n",
    "pl.subplot(1,2,2)\n",
    "pl.plot(X_scaled[:,2][class0],X_scaled[:,3][class0],'o',c='red', label=names[0])\n",
    "pl.plot(X_scaled[:,2][class1],X_scaled[:,3][class1],'o',c='blue', label=names[1])\n",
    "pl.plot(X_scaled[:,2][class2],X_scaled[:,3][class2],'o',c='green', label=names[2])\n",
    "pl.grid()\n",
    "pl.legend()\n",
    "pl.xlabel(feature_names[2])\n",
    "pl.ylabel(feature_names[3])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJl9pJfQsPa"
   },
   "source": [
    "**Redes Neuronales con Pytorch**\n",
    "\n",
    "Vamos a crear una red neuronal de 3 capas lineales, las dos primeras tendrán funciones de activación tipo ReLU y la última una función de activación tipo Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWU-FUmfQs1X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Importamos el paquete torch\n",
    "import torch\n",
    "from torch.autograd import Variable # Para convertir los datos a tensores\n",
    "\n",
    "#--- Definimos la secuencia de capas de la ANN\n",
    "input_dim = X_train.shape[1]\n",
    "model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(input_dim, 50),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(50, 50),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(50, input_dim),\n",
    "                torch.nn.Softmax(dim=1)\n",
    "                )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xfhs-B1BQvAS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Definimos el optimizador y el criterio de evaluación\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24SCAfIFQwUU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos el número de épocas\n",
    "\n",
    "n_epoch  = 100\n",
    "\n",
    "#-- Convertimos los datos a tensores\n",
    "X_train_tensor = Variable(torch.from_numpy(X_train)).float()\n",
    "Y_train_tensor = Variable(torch.from_numpy(Y_train)).long()\n",
    "X_test_tensor  = Variable(torch.from_numpy(X_test)).float()\n",
    "Y_test_tensor  = Variable(torch.from_numpy(Y_test)).long()\n",
    "\n",
    "#-- Definimos párametros para almacenar la evalaución el entrenamiento de la red en función del número de épocas\n",
    "loss_list     = np.zeros(n_epoch)\n",
    "accuracy_list = np.zeros(n_epoch)\n",
    "\n",
    "#-- Iniciamos el entrenamiento\n",
    "for epoch in range(n_epoch):\n",
    "    Y_pred = model(X_train_tensor)\n",
    "    loss = criterion(Y_pred, Y_train_tensor)\n",
    "    loss_list[epoch] = loss.item()\n",
    "\n",
    "    # Gradiente Cero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Nuevo paso\n",
    "    optimizer.step()\n",
    "\n",
    "    correct = (torch.argmax(Y_pred, dim=1) == Y_train_tensor).type(torch.FloatTensor)\n",
    "    accuracy_list[epoch] = correct.mean()\n",
    "\n",
    "    print('Epoch [{}/{}], loss: {}, acc: {}'.format(epoch+1,n_epoch,loss_list[epoch],accuracy_list[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9Lq9lzJQxud",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Graficamos la precisión y la perdida para el set de entrenamiento\n",
    "fig = pl.figure(figsize=(10, 4))\n",
    "pl.subplot(1,2,1)\n",
    "pl.plot(accuracy_list)\n",
    "pl.ylabel(\"training accuracy\")\n",
    "pl.xlabel(\"epcohs\")\n",
    "pl.grid()\n",
    "\n",
    "pl.subplot(1,2,2)\n",
    "pl.plot(loss_list)\n",
    "pl.ylabel(\"training loss\")\n",
    "pl.xlabel(\"epochs\")\n",
    "pl.grid()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8WmZbPzQzHe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos con el set de testeo\n",
    "\n",
    "Y_pred = model(X_test_tensor)\n",
    "loss = criterion(Y_pred, Y_test_tensor)\n",
    "correct = (torch.argmax(Y_pred, dim=1) == Y_test_tensor).type(torch.FloatTensor)\n",
    "\n",
    "print('Loss: {}, Acc:{}'.format(loss, correct.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lRr3XF2RiZs"
   },
   "source": [
    "## **7.3 Imágenes como tipos de datos**\n",
    "\n",
    "Las imágenes son un tipo de datos fundamental para un científico de datos que aborda tareas de visión por computadora. A diferencia de otros tipos de datos, las imágenes son multidimensionales y contienen información enriquecida además de su tamaño (alto x ancho). Cada píxel también lleva consigo información de intensidad, de modo que un objeto tipo imagen tiene un tamaño (alto, ancho), y cada coordenada tiene un valor de intensidad en una escala de 0 a 1.\n",
    "\n",
    "<center><img src=\"./img/gatogris.jpeg\"></center>\n",
    "\n",
    "Por otro lado, las imágenes a color poseen 3 canales diferentes asociados a las escalas RGB (Rojo, Verde y Azul). Por lo tanto, el tamaño de un objeto tipo imagen a color es (alto, ancho, canales), donde cada píxel contiene información de intensidad en las escalas roja, verde y azul. Esta escala varía entre 0 y 255, a diferencia de la escala de grises.\n",
    "\n",
    "<center><img src=\"./img/gatocolores.png\" width=\"40%\"></center>\n",
    "\n",
    "Algunas imágenes contienen un cuarto canal asociado al brillo de cada píxel. En este caso, el número de canales es 4 y se reconocen como escalas RGBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Métricas de evaluación\n",
    "\n",
    "Por lo general, los problemas que se abordan mediante el uso de imágenes en el área de visión por computadora buscan clasificar diferentes tipos de objetos. Para evaluar la eficiencia de los modelos en su tarea de clasificación, existen diversas métricas.eficiencia de los modelos en su tarea de clasificación existen diferentes métricas.\n",
    "\n",
    "**Matriz de Confusión**\n",
    "\n",
    "La matriz de confusión es una herramienta que se utiliza en clasificación para evaluar el rendimiento de un modelo. La matriz muestra el número de verdaderos positivos (TP), verdaderos negativos (TN), falsos positivos (FP) y falsos negativos (FN). La disposición general de la matriz es la siguiente:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "    TN & FP \\\\\n",
    "    FN & TP \\\\\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "Verdaderos Positivos (TP): Instancias positivas que fueron clasificadas correctamente como positivas.\n",
    "Verdaderos Negativos (TN): Instancias negativas que fueron clasificadas correctamente como negativas.\n",
    "Falsos Positivos (FP): Instancias negativas que fueron incorrectamente clasificadas como positivas (error tipo I).\n",
    "Falsos Negativos (FN): Instancias positivas que fueron incorrectamente clasificadas como negativas (error tipo II).\n",
    "\n",
    "<br>\n",
    "\n",
    "**F1 Score**\n",
    "\n",
    "El F1 Score es una métrica que combina la precisión y la cobertura (recall) en un solo valor. Se calcula mediante la fórmula:\n",
    "\n",
    "$$\n",
    "F1 = 2\\frac{Precision\\cdot Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "Precision: Porcentaje de instancias clasificadas como positivas que son realmente positivas.\n",
    "Recall (Cobertura): Porcentaje de instancias positivas que son correctamente clasificadas.\n",
    "\n",
    "El F1 Score es útil cuando hay un desequilibrio entre las clases.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Precision**\n",
    "\n",
    "La precisión se define como el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos positivos. Mide la exactitud de las instancias clasificadas como positivas.\n",
    "\n",
    "$$Precision=\\frac{Verdaderos\\, Positivos}{Verdaderos\\, Positivos + Falsos\\, Positivos}$$\n",
    "\n",
    "**Cobertura (Recall)**\n",
    "\n",
    "La cobertura, también conocida como recall o sensibilidad, se define como el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos negativos. Mide la capacidad del modelo para capturar todas las instancias positivas.\n",
    "\n",
    "$$Recall=\\frac{Verdaderos\\,Positivos}{Verdaderos\\, Positivos+Falsos\\, Negativos}$$\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "La exactitud (Accuracy) es una medida general del rendimiento del modelo y se define como la proporción de instancias correctamente clasificadas con respecto al total de instancias.\n",
    "\n",
    "$$Accuracy=\\frac{Verdaderos\\, Positivos+Verdaderos\\, Negativos}{Total\\, de\\, Instancias}$$\n",
    "\n",
    "Es importante considerar el contexto y el desequilibrio de clases al interpretar estas métricas. Cada métrica proporciona información valiosa sobre aspectos específicos del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3knYQ2nqRk4r"
   },
   "source": [
    "#### **Ejercicio:** Métricas de evaluación\n",
    "\n",
    "En este ejercicio identificaremos uno de los errores más comúnes al momento de entrenar modelos de aprendizaje; el cruce de datos de entrenamiento y evaluación.\n",
    "\n",
    "Para identificar este error visualizaremos curvas de *loss*, *f1_score* y *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ArZPQJwRoVR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Descomprimimos el dataset\n",
    "#!unzip data/mnist.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFfL8x8LRpm6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Buscamos las direcciones de cada archivo de imagen\n",
    "from glob import glob\n",
    "\n",
    "train_files = glob('./mnist/train/*/*.png')\n",
    "valid_files = glob('./mnist/valid/*/*.png')\n",
    "test_files = glob('./mnist/test/*/*.png')\n",
    "\n",
    "train_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0nid1k3Rqjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Ordenamos los datos de forma aleatoria para evitar sesgos\n",
    "import numpy as np\n",
    "\n",
    "np.random.shuffle(train_files)\n",
    "np.random.shuffle(valid_files)\n",
    "np.random.shuffle(test_files)\n",
    "\n",
    "len(train_files), len(valid_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIFhLqV9Rt6G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cargamos los datos de entrenamiento en listas\n",
    "from PIL import Image\n",
    "\n",
    "N_train = len(train_files)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i, train_file in enumerate(train_files):\n",
    "    Y_train.append( int(train_file.split('/')[3]) )\n",
    "    X_train.append(np.array(Image.open(train_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNIyN_JlRvG8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cargamos los datos de validación en listas\n",
    "N_valid = len(valid_files)\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "\n",
    "for i, valid_file in enumerate(valid_files):\n",
    "    Y_valid.append( int(valid_file.split('/')[3]) )\n",
    "    X_valid.append( np.array(Image.open(valid_file)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2Z7a6XLRwmD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cargamos los datos de testeo en listas\n",
    "N_test = len(test_files)\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for i, test_file in enumerate(test_files):\n",
    "    Y_test.append( int(test_file.split('/')[3]) )\n",
    "    X_test.append( np.array(Image.open(test_file)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4B6SkDbRx5D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Visualizamos el tamaño de cada subset\n",
    "len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7KFKp0RRy3J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Visualizamos la distribución de clases en cada subset\n",
    "from PIL import Image\n",
    "\n",
    "fig = pl.figure(figsize=(15,5))\n",
    "pl.subplot(1,3,1)\n",
    "pl.hist(np.sort(Y_train))\n",
    "pl.xlabel('class')\n",
    "pl.ylabel('counts')\n",
    "pl.title('Train set')\n",
    "\n",
    "pl.subplot(1,3,2)\n",
    "pl.hist(np.sort(Y_valid))\n",
    "pl.xlabel('class')\n",
    "pl.ylabel('counts')\n",
    "pl.title('Valid set')\n",
    "\n",
    "pl.subplot(1,3,3)\n",
    "pl.hist(np.sort(Y_test))\n",
    "pl.xlabel('class')\n",
    "pl.ylabel('counts')\n",
    "pl.title('Test set')\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7JL5hPQR1FD"
   },
   "source": [
    "Este dataset cuenta con un total de 900 objetos (600 para entrenamiento, 200 para validación y 100 para testeo). Este conjunto de datos es un ejemplo donde las clases están balanceadas, no siempre se tendrán datos de esta forma y se tendrán que usar técnicas de aumentación de datos.\n",
    "\n",
    "Considerando el total de datos de este dataset,~66% son datos de entrenamiento, otro ~22% de validación y un ~11% para testeo. Esto representa un buen ejemplo de cómo distribuir los datos para entrenar un modelo de aprendizaje profundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-x4w9gdR2gJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Visualizamos los datos\n",
    "fig = pl.figure(figsize=(8,8))\n",
    "for i in range(4):\n",
    "    pl.subplot(2,2,i+1)\n",
    "    pl.imshow(X_test[i*15])\n",
    "    pl.title(Y_test[i*15])\n",
    "    pl.axis(False)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tezKSiVR4At",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Convertimos las listas de datos a tensores de torch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X_train = Variable(torch.from_numpy(np.array(X_train))).float()\n",
    "Y_train = Variable(torch.from_numpy(np.array(Y_train))).long()\n",
    "\n",
    "X_valid = Variable(torch.from_numpy(np.array(X_valid))).float()\n",
    "Y_valid = Variable(torch.from_numpy(np.array(Y_valid))).long()\n",
    "\n",
    "X_test = Variable(torch.from_numpy(np.array(X_test))).float()\n",
    "Y_test = Variable(torch.from_numpy(np.array(Y_test))).long()\n",
    "\n",
    "X_train.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fuo_MuVeR50t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos una NN con dos capas ocultas lineales de 100 neuronas\n",
    "input_dim = 28*28\n",
    "out_dim = 10\n",
    "hidden = 100\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(input_dim, hidden),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(hidden, out_dim)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS1uXkKIR7QD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score # Nueva métrica (La revisaremos la próóxima sesión)\n",
    "\n",
    "#-- Número de épocas\n",
    "n_epoch = 100\n",
    "\n",
    "#-- Listas de evaluación entrenamiento\n",
    "loss_train = []\n",
    "f1_train = []\n",
    "acc_train = []\n",
    "\n",
    "#-- Listas de evaluación validación\n",
    "loss_valid = []\n",
    "f1_valid = []\n",
    "acc_valid = []\n",
    "\n",
    "#-- Entrenamineto de la ANN\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "\n",
    "    Xtr = X_train.view(X_train.size(0), -1)\n",
    "    Y_pred = model(Xtr)\n",
    "\n",
    "    loss = criterion(Y_pred,Y_train)\n",
    "    loss_train.append(loss.item())\n",
    "\n",
    "    Y_pred = torch.argmax(Y_pred, 1)\n",
    "    f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n",
    "\n",
    "    acc = sum(Y_train == Y_pred)/len(Y_pred)\n",
    "    acc_train.append(acc)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch,loss_train[-1], f1_train[-1], acc_train[-1]) )\n",
    "\n",
    "    model.eval()\n",
    "    Xvl = X_valid.view(X_valid.size(0), -1)\n",
    "    Y_pred = model(Xvl)\n",
    "    loss = criterion(Y_pred,Y_valid)\n",
    "    loss_valid.append(loss.item())\n",
    "\n",
    "    Y_pred = torch.argmax(Y_pred, 1)\n",
    "    f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n",
    "\n",
    "    acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "    acc_valid.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-HTsdBdR9UR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Visualizamos las curvas de entrenamiento y validación\n",
    "\n",
    "fig = pl.figure(figsize=(12,3))\n",
    "pl.subplot(1,3,1)\n",
    "pl.plot(range(n_epoch), loss_train, label='train')\n",
    "pl.plot(range(n_epoch), loss_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,2)\n",
    "pl.plot(range(n_epoch), f1_train, label='train')\n",
    "pl.plot(range(n_epoch), f1_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('f1_score')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,3)\n",
    "pl.plot(range(n_epoch), acc_train, label='train')\n",
    "pl.plot(range(n_epoch), acc_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('accuracy')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLaT3MY6R_fA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos el modelo entrenado con el set de testeo\n",
    "model.eval()\n",
    "\n",
    "Xts = X_test.view(X_test.size(0), -1)\n",
    "Y_pred = model(Xts)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos el modelo entrenado con el set de entrenamiento\n",
    "model.eval()\n",
    "\n",
    "Xt = X_train.view(X_train.size(0), -1)\n",
    "Y_pred = model(Xt)\n",
    "loss = criterion(Y_pred,Y_train)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_train, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_train == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGaotb-AT28R"
   },
   "source": [
    "### 7.3.1 Overfitting y Regularización\n",
    "\n",
    "El **overfitting** o sobreajuste es otro problema común al entrenar un modelo de aprendizaje automático. Consiste en entrenar modelos que aprenden a la perfección los datos de entrenamiento, perdiendo de esta forma generalidad. De modo, que si al modelo se le pasan datos nuevos que jamás ha visto, no será capaz de realizar una buena predicción.\n",
    "\n",
    "Existe un problema opuesto al overfitting conocido como **underfitting** o subajuste, en el que el modelo no logra realizar una predicción ni siquiera cercana a los datos de entrenamiento y esta lejos de hacer una generalización.\n",
    "\n",
    "<center><img src=\"./img/overfitting.png\"></center>\n",
    "\n",
    "Para evitar el underfitting y el overfitting se pueden utilizar curvas de **loss**, **f1_score** o **accuracy** utilizando los datos de entrenamiento y validación. Haciendo un análisis sobre estas curvas se logra identificar estos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXTQwnOdT3S6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos una función que nos permita entrenar diferentes modelos de ANN\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_valid(model, n_epoch, optimizer, criterion):\n",
    "    loss_train = []\n",
    "    f1_train = []\n",
    "    acc_train = []\n",
    "\n",
    "    loss_valid = []\n",
    "    f1_valid = []\n",
    "    acc_valid = []\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "\n",
    "        Xtr = X_train.view(X_train.size(0), -1)\n",
    "        Y_pred = model(Xtr)\n",
    "\n",
    "        loss = criterion(Y_pred,Y_train)\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "        f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n",
    "\n",
    "        acc = sum(Y_train == Y_pred)/len(Y_pred)\n",
    "        acc_train.append(acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch,loss_train[-1], f1_train[-1], acc_train[-1]) )\n",
    "\n",
    "        model.eval()\n",
    "        Xvl = X_valid.view(X_valid.size(0), -1)\n",
    "        Y_pred = model(Xvl)\n",
    "        loss = criterion(Y_pred,Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "        f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n",
    "\n",
    "        acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "        acc_valid.append(acc)\n",
    "\n",
    "fig = pl.figure(figsize=(12,3))\n",
    "pl.subplot(1,3,1)\n",
    "pl.plot(range(n_epoch), loss_train, label='train')\n",
    "pl.plot(range(n_epoch), loss_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,2)\n",
    "pl.plot(range(n_epoch), f1_train, label='train')\n",
    "pl.plot(range(n_epoch), f1_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('f1_score')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,3)\n",
    "pl.plot(range(n_epoch), acc_train, label='train')\n",
    "pl.plot(range(n_epoch), acc_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('accuracy')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIVQYxYlT_kE"
   },
   "source": [
    "### **7.3.2.1 Underfitting**\n",
    "\n",
    "El **underfitting** o sub ajuste se puede presentar en las siguientes situaciones:\n",
    "\n",
    "* **Finalización temprana**: Cuando el modelo se entrena hasta una época temprana a pesar de que la tendencia indica una posible obtención de mejores resultados.\n",
    "\n",
    "* **Modelo Simple**: Cuando el modelo es tan básico que no es capaz de extraer ningún tipo de patrón efectivo que le permita hacer una generalización de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SybWJx6TUAzR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos una ANN simple para identificar un error de underfitting\n",
    "input_dim = 28*28\n",
    "out_dim = 10\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(input_dim, out_dim)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_valid(model,30,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZziEuCMUCFd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos el modelo entrenado con el set de testeo\n",
    "model.eval()\n",
    "\n",
    "Xts = X_test.view(X_test.size(0), -1)\n",
    "Y_pred = model(Xts)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0TcunLBUEHI"
   },
   "source": [
    "### **7.3.2.2 Overfitting**\n",
    "\n",
    "El **overfitting** o sobreajuste es el caso opuesto al subajuste y se puede presentar en la siguiente situación:\n",
    "una obtención de mejores resultados.\n",
    "\n",
    "* **Modelo Complejo**: El modelo es tan complejo que aprendió perfectamente los datos de entrenamiento, perdiendo generalidad. Cuando el modelo vea datos nuevos, diferentes a los del entrenamiento, su predicción será errónea.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOWoWHZLUDVe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "out_dim = 10\n",
    "hidden = 60\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dim, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, out_dim)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_valid(model,200,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceRzy3ihUIdI"
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos el modelo entrenado con el set de testeo\n",
    "model.eval()\n",
    "\n",
    "Xts = X_test.view(X_test.size(0), -1)\n",
    "Y_pred = model(Xts)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hrn2JHxUHsd"
   },
   "source": [
    "### **7.3.2.3 Regularización**\n",
    "\n",
    "Un mecanismo que permite evitar el sobreajuste es conocido como **regularización**. La cantidad de regularización afectará el rendimiento de validación del modelo. Muy poca regularización no resolverá el problema de sobreajuste. Demasiada regularización hará que el modelo sea mucho menos efectivo. La regularización actúa como una restricción sobre el conjunto de posibles funciones aprendibles.\n",
    "\n",
    "<br>\n",
    "\n",
    "Según [Ian Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow), \"*La regularización es cualquier modificación que hacemos a un algoritmo de aprendizaje que tiene como objetivo reducir su error de generalización pero no su error de entrenamiento.*\"\n",
    "\n",
    "<br>\n",
    "\n",
    "**Regularización de caída de peso**\n",
    "\n",
    "La pérdida de peso es la técnica de regularización más común (implementada en Pytorch). En PyTorch, la caída de peso se proporciona como un parámetro para el optimizador *decay_weight*. En [este](https://pytorch.org/docs/stable/optim.html) enlace se muestran otros parámetros que pueden ser usados en los optimizadores.\n",
    "\n",
    "A la caída de peso también se le llama:\n",
    "  * L2\n",
    "  * Ridge\n",
    "\n",
    "Para la disminución de peso, agregamos un término de penalización en la actualización de los pesos:\n",
    "\n",
    "$w(x) = w(x) − \\eta \\nabla x - \\alpha \\eta x$\n",
    "\n",
    "Este nuevo término en la actualización lleva los parámetros $w$ ligeramente hacia cero, agregando algo de **decaimiento** en los pesos con cada actualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QyfKSswUL2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "out_dim = 10\n",
    "hidden = 60\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dim, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, out_dim)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_valid(model,100,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-V5YeGhUNo_",
    "tags": []
   },
   "outputs": [],
   "source": [
    " #-- Evaluamos el modelo entrenado con el set de testeo\n",
    "model.eval()\n",
    "\n",
    "Xts = X_test.view(X_test.size(0), -1)\n",
    "Y_pred = model(Xts)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBEZk3UrUPwI"
   },
   "source": [
    "## **7.4 Exploración de metaparametros**\n",
    "\n",
    "Una de las tareas fundamentales al momento de diseñar un modelo de aprendizaje automático es la selección de los parámetros del modelo (metaparámetros), hasta el momento los parámetros que hemos utilizados han sido:\n",
    "\n",
    "* **n_layers** = Número de capas\n",
    "* **n_neurons** = Número de neuronas\n",
    "* **n_epoch** = Número de épocas\n",
    "* **lr** = Tasa de aprendizaje - learning rate\n",
    "* **weight_decay** = peso de decaímiento\n",
    "\n",
    "Sin embargo uno de los metaparámetros más importantes al momento de entrenar una NN es el tamaño de los datos con el que el modelo aprende. \n",
    "El **batch_size** es un parámetro que regula el tamaño de los datos que el modelo utiliza para entrenarse.\n",
    "\n",
    "* **batch_size** = Tamaño del subconjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzKLrvJ6URTn"
   },
   "source": [
    "#### **Ejercicio: Batch_size**\n",
    "\n",
    "Utilizar el metaparametro **batch_size** y compare su resultados de *loss*, *f1_score* y *accuracy* para un modelo similar utilizando diferentes épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1KDd76oUVNx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos una ANN simple sin utilizar batch_size\n",
    "\n",
    "input_dim = 28*28\n",
    "out_dim = 10\n",
    "hidden = 50\n",
    "\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.01\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(input_dim, hidden),\n",
    "  torch.nn.Tanh(),\n",
    "  torch.nn.Linear(hidden, hidden),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(hidden, hidden),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(hidden, out_dim)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOQGY1qzUXVA"
   },
   "source": [
    "**Modelo entrenado en 15 épocas sin batch_size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_xt4g-TUYM4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_epoch = 15\n",
    "\n",
    "loss_train = []\n",
    "f1_train = []\n",
    "acc_train = []\n",
    "\n",
    "loss_valid = []\n",
    "f1_valid = []\n",
    "acc_valid = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    Xtr = X_train.view(X_train.size(0), -1)\n",
    "    Y_pred = model(Xtr)\n",
    "\n",
    "    loss = criterion(Y_pred,Y_train)\n",
    "    loss_train.append(loss.item())\n",
    "\n",
    "    Y_pred = torch.argmax(Y_pred, 1)\n",
    "    f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n",
    "\n",
    "    acc = sum(Y_train == Y_pred)/len(Y_pred)\n",
    "    acc_train.append(acc)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch,loss_train[-1], f1_train[-1], acc_train[-1]) )\n",
    "\n",
    "    model.eval()\n",
    "    Xvl = X_valid.view(X_valid.size(0), -1)\n",
    "    Y_pred = model(Xvl)\n",
    "    loss = criterion(Y_pred,Y_valid)\n",
    "    loss_valid.append(loss.item())\n",
    "\n",
    "    Y_pred = torch.argmax(Y_pred, 1)\n",
    "    f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n",
    "\n",
    "    acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "    acc_valid.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmdW7UyUUZjJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(12,3))\n",
    "pl.subplot(1,3,1)\n",
    "pl.plot(range(n_epoch), loss_train, label='train')\n",
    "pl.plot(range(n_epoch), loss_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,2)\n",
    "pl.plot(range(n_epoch), f1_train, label='train')\n",
    "pl.plot(range(n_epoch), f1_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('f1_score')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,3)\n",
    "pl.plot(range(n_epoch), acc_train, label='train')\n",
    "pl.plot(range(n_epoch), acc_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('accuracy')\n",
    "pl.legend()\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_2hL_3bUazD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos el modelo entrenado con el set de testeo\n",
    "model.eval()\n",
    "\n",
    "Xts = X_test.view(X_test.size(0), -1)\n",
    "Y_pred = model(Xts)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDs_FZY3UcBc"
   },
   "source": [
    "### **7.4.1 Batch Size**\n",
    "El **batch_size** es un metaparametro que permite seleccionar muestras de datos más pequeñas que el conjunto completo de datos. Usar subconjuntos en el proceso de entrenamiento en vez del conjunto completo, es altamente eficiente desde el punto de vista computacional. De modo que se puede obtener un modelo de igual capacidad usando un menor número de épocas.\n",
    "\n",
    "<center><img src='./img/epoch_bs_iter.jpg' width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMdh66l1UeAG"
   },
   "source": [
    "**Modelo entrenado en 5 épocas con batch_size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssY-d06SUez3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_ds = TensorDataset(X_train, Y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNigx2foUfv1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos una ANN simple sin utilizar batch_size\n",
    "\n",
    "input_dim = 28*28\n",
    "out_dim = 10\n",
    "hidden = 50\n",
    "\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.01\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(input_dim, hidden),\n",
    "  torch.nn.Tanh(),\n",
    "  torch.nn.Linear(hidden, hidden),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(hidden, hidden),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(hidden, out_dim)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFe53ol4Ug28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "\n",
    "loss_train = []\n",
    "f1_train = []\n",
    "acc_train = []\n",
    "\n",
    "loss_valid = []\n",
    "f1_valid = []\n",
    "acc_valid = []\n",
    "\n",
    "total_it = 0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for batch_id, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n",
    "        model.train()\n",
    "\n",
    "        Xtr = X_train_batch.view(X_train_batch.size(0), -1)\n",
    "        Y_pred = model(Xtr)\n",
    "\n",
    "        loss = criterion(Y_pred,Y_train_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "        f1_train.append( f1_score(Y_train_batch,Y_pred, average='macro') )\n",
    "\n",
    "        acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n",
    "        acc_train.append(acc)\n",
    "\n",
    "        model.eval()\n",
    "        Xvl = X_valid.view(X_valid.size(0), -1)\n",
    "        Y_pred = model(Xvl)\n",
    "        loss = criterion(Y_pred,Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "        f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n",
    "\n",
    "        acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "        acc_valid.append(acc)\n",
    "\n",
    "        total_it += 1\n",
    "\n",
    "    print( 'Epoch [{}/{}], loss: {}. f1:{} acc: {} '.format(epoch+1,n_epoch, loss_train[-1], f1_train[-1], acc_train[-1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFEpX-JjUh4M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(15,5))\n",
    "pl.subplot(1,3,1)\n",
    "pl.plot(range(total_it), loss_train, label='train')\n",
    "# plt.plot(range(total_it), loss_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('loss')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,2)\n",
    "pl.plot(range(total_it), f1_train, label='train')\n",
    "pl.plot(range(total_it), f1_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('f1_score')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.subplot(1,3,3)\n",
    "pl.plot(range(total_it), acc_train, label='train')\n",
    "pl.plot(range(total_it), acc_valid, label='valid')\n",
    "pl.xlabel('n_epoch')\n",
    "pl.ylabel('accuracy')\n",
    "pl.legend()\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ANZFvmUUjAL",
    "tags": []
   },
   "outputs": [],
   "source": [
    " #-- Evaluamos el modelo entrenado con el set de testeo\n",
    "model.eval()\n",
    "\n",
    "Xts = X_test.view(X_test.size(0), -1)\n",
    "Y_pred = model(Xts)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print('loss: {}, f1: {}, acc: {}'.format(loss.item(), f1, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lsYmhdxUm1W"
   },
   "source": [
    "### **7.4.2 Exploración de Metaparámetros**\n",
    "\n",
    "La exploración de metaparámetros consiste en la búsqueda de los valores óptimos de estos parámetros que me arrojan los mejores resultados (*loss*, *f1_score* y el *accuracy*), evitando los problemas en el cruze de subsets, underfitting y overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b5rUc6WUosz"
   },
   "source": [
    "#### **7.4.2.1 Técnicas de Validación**\n",
    "\n",
    "Las técnicas de validación consisten en la búsqueda de los metaparametros que mejor resultados nos retornan, las técnicas de validación comúnmente utilizadas son el **K-fold** y el **Grid search**.\n",
    "\n",
    "**K-fold**\n",
    "\n",
    "La validación cruzada k-Fold es una técnica utilizada en aprendizaje automático para evaluar el rendimiento de un modelo. El conjunto de datos se divide en k subconjuntos (o \"fold\"), y el modelo se entrena k veces, cada vez utilizando k-1 subconjuntos como datos de entrenamiento y el subconjunto restante como datos de validación. Se repite este proceso k veces, utilizando un subconjunto diferente como datos de validación en cada iteración. Finalmente, se promedian los resultados de evaluación obtenidos en cada iteración para obtener una métrica de rendimiento general del modelo.\n",
    "\n",
    "Esta técnica es especialmente útil cuando el conjunto de datos es limitado, ya que maximiza el uso de los datos para entrenamiento y validación.\n",
    "\n",
    "<center><img src='./img/kfold.png'></center>\n",
    "\n",
    "\n",
    "**Grid Search**\n",
    "\n",
    "La búsqueda de cuadrícula (Grid Search) es una técnica utilizada para ajustar los hiperparámetros de un modelo de aprendizaje automático con el objetivo de encontrar la combinación óptima que maximice el rendimiento del modelo. Se seleccionan diferentes valores posibles para cada hiperparámetro, y se evalúa el modelo utilizando todas las combinaciones posibles de estos valores.\n",
    "\n",
    "Por ejemplo, si se tienen dos hiperparámetros A y B con tres posibles valores cada uno, la búsqueda de cuadrícula evaluará el modelo para las combinaciones (A1, B1), (A1, B2), (A1, B3), (A2, B1), ..., (A3, B3). Luego, se selecciona la combinación que proporciona el mejor rendimiento según una métrica predefinida, como precisión, F1-score, etc.\n",
    "\n",
    "La búsqueda de cuadrícula es una herramienta valiosa para encontrar la configuración óptima de un modelo, pero puede volverse costosa computacionalmente, especialmente cuando se exploran numerosas combinaciones de hiperparámetros.\n",
    "\n",
    "<center><img src='./img/grid_search.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjkrNF-bUqU5"
   },
   "source": [
    "##### **Ejercicio: Grid Search**\n",
    "\n",
    "Utilizar la técnica de validación **Grid Search** para encontrar los parámetros óptimos que mejor permiten clasificar el dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYt_pvwqUvxy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos una función para calcular la matriz de confusión\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def CM(Y_true, Y_pred, classes):\n",
    "    fig = pl.figure(figsize=(5, 5))\n",
    "    cm = confusion_matrix(Y_true, Y_pred)\n",
    "    lclasses = np.arange(0,classes)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cmap=pl.cm.Blues\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax, pad=0.01, shrink=0.86)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),xticklabels=lclasses, yticklabels=lclasses)\n",
    "    ax.set_xlabel(\"Predicted\",size=10)\n",
    "    ax.set_ylabel(\"True\",size=10)\n",
    "    ax.set_ylim(classes-0.5, -0.5)\n",
    "\n",
    "    pl.setp(ax.get_xticklabels(), size=12)\n",
    "    pl.setp(ax.get_yticklabels(), size=12)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max()/2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\",size=10 , color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlRTU9DSUvbE"
   },
   "source": [
    "# Metaparametros\n",
    "\n",
    "* **n_layers** = Número de capas\n",
    "* **n_neurons** = Número de neuronas\n",
    "* **n_epoch** = Número de épocas\n",
    "* **lr** = Tasa de aprendizaje - learning rate\n",
    "* **weight_decay** = peso de decaímiento\n",
    "* **batch_size** = Tamaño del subconjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atnL8gjMUyb-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_valid(model, n_epoch, optimizer, criterion):\n",
    "    loss_train = []\n",
    "    f1_train = []\n",
    "    acc_train = []\n",
    "\n",
    "    loss_valid = []\n",
    "    f1_valid = []\n",
    "    acc_valid = []\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "\n",
    "        Xtr = X_train.view(X_train.size(0), -1)\n",
    "        Y_pred = model(Xtr)\n",
    "\n",
    "        loss = criterion(Y_pred,Y_train)\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "        f1_train.append( f1_score(Y_train,Y_pred, average='macro') )\n",
    "\n",
    "        acc = sum(Y_train == Y_pred)/len(Y_pred)\n",
    "        acc_train.append(acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        Xvl = X_valid.view(X_valid.size(0), -1)\n",
    "        Y_pred = model(Xvl)\n",
    "        loss = criterion(Y_pred,Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "        f1_valid.append( f1_score(Y_valid, Y_pred, average='macro') )\n",
    "\n",
    "        acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "        acc_valid.append(acc)\n",
    "\n",
    "    print( 'Valid Evaluation loss: {}. f1:{} acc: {} '.format(loss_valid[-1], f1_valid[-1], acc_valid[-1]) )\n",
    "    CM(Y_valid, Y_pred, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhPA2r87Uzch",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm.notebook import  tqdm\n",
    "\n",
    "\n",
    "bs_list = [256,512,1024]\n",
    "lr_list = [0.001,0.01,0.1]\n",
    "wd_list = [0.001,0.01,0.1]\n",
    "hd_list = [50,80,100]\n",
    "ne_list = [50,100,150]\n",
    "\n",
    "pbar = tqdm(total=len(bs_list)*len(lr_list)*len(wd_list)*len(hd_list)*len(ne_list))\n",
    "\n",
    "for ne in ne_list:\n",
    "    for bs in bs_list:\n",
    "        train_ds = TensorDataset(X_train, Y_train)\n",
    "        train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "        for lr in lr_list:\n",
    "            for wd in wd_list:\n",
    "                for hd in hd_list:\n",
    "                    input_dim = 28*28\n",
    "                    out_dim = 10\n",
    "                    hidden = hd\n",
    "\n",
    "                    model = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(input_dim, hidden),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(hidden, out_dim)\n",
    "                    )\n",
    "\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "                    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "                    print('ne: {}, hd:{}, wd:{}, lr: {}, bs:{} '.format(ne,hd,wd,lr,bs))\n",
    "                    train_valid(model,ne,optimizer,criterion)\n",
    "                    print('###################\\n')\n",
    "\n",
    "                    pbar.update()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOzxZsYU33D"
   },
   "source": [
    "## **7.5 Redes Neuronales Convolucionales**\n",
    "\n",
    "Una red neuronal convolucional CNN es una de las ANN más comunes y usadas actualmente. Este tipo de red es una variación de un MLP, sin embargo, debido a que su aplicación es realizada en matrices bidimensionales, son muy efectivas para tareas de visión por computador, especificamente en tareas de clasificación y segmentación de imágenes.\n",
    "\n",
    "<center><img src='./img/cnn.png' width=\"70%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dICBQFm3U6md"
   },
   "source": [
    "### **7.5.1 Capas de una CNN**\n",
    "\n",
    "\n",
    "**Capas Convolucionales**\n",
    "\n",
    "A diferencia de las capas densamente conectadas (**Linear**) las redes convolucionales se componen principalmente de capas de convolución que reciben como parámetro de entrada el número de canales que componen el mapa bidimensional (en el caso de la primera capa convolucional es la imagen original). Para imágenes en escala de gris, en numero de canales es 1. En el caso de imágenes a color se podría trata de 3 (RGB) o 4 (RGBA) canales. La salida de una capa convolucional son un número de canales seleccionado. Cada canal tiene un mapa de características asociado y se obtiene al aplicar un kernel (filtro) sobre el mapa de entrada.\n",
    "\n",
    "**Kernel**\n",
    "\n",
    "**Ejemplo**:\n",
    "\n",
    "* *Input (x)*: 3x3\n",
    "* *Kernel (w)*: 2x2\n",
    "* *Output (z)*: 2x2\n",
    "\n",
    "El kernel hace una convolución por toda la imagen, de izquierda a derecha y de arriba a abajo, de modo que la salida es un mapa de características bidimensional donde en valor de cada entrada del mapa corresponde al producto $w*x$. Así por ejemplo, 0x0+ 1x1 + 2x3 + 4x3 = 19.\n",
    "\n",
    "<center><img src=\"./img/correlation.png\"></center>\n",
    "\n",
    "Los kernel son definidos aleatoriamente por Pytorch, sin embargo, es posible pasarle un filtro específico para efectuar la convolución.\n",
    "\n",
    "**Padding**\n",
    "\n",
    "De acuerdo al ejemplo de la imagen anterior al realizar la convolución, el tamaño del mapa de salida es menor que el tamaño del de entrada. Para evitar esta perdida de información en los bordes se puede utilizar el parametro *padding*. Este parámetro agrega información en los bordes, de modo que al pasar el kernel sobre todo el mapa, se recupera el tamaño inicial. El contenido de estos bordes extra depende del parámetro *padding_mode*, que toma por defecto el valor 'zeros'. En la imagen de ejemplo se aplica un padding igual a 1 y se utilizan ceros como valores por defecto. Más infromación [aquí](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
    "\n",
    "<center><img src=\"./img/conv-pad.png\"></center>\n",
    "\n",
    "\n",
    "**Stride**\n",
    "\n",
    "Otro parámetro importante en la capa convolucional es el espacio entre cada aplicación del kernel, el kernel por defecto y luego de ejecutado, salta hacia la derecha un paso. Cuando termina horizontalmente, hace un salto vertical arrancando nuevamente desde la izquierda, así hasta barrer toda la imagen.\n",
    "El valor de estos saltos horizontales y verticales se puede definir usando el parámetro *stride*. En la imagen de ejemplo se aplica un stride de la forma (2,3), dando como resultado una salida de tamaño 2x2.\n",
    "\n",
    "<center><img src=\"./img/conv-stride.png\"></center>\n",
    "\n",
    "\n",
    "**Max Pooling y Global Average Pooling**\n",
    "\n",
    "La idea detrás de la técnica *Pooling* es perder resolución en la imagen para obtener las características más representativas de la imagen. El *max pooling* consiste en tomar el valor máximo de un kernel de *pooling* proyectáándolo en el mapa de salida. Una variedad de este método consiste en tomar el promedio global del kernel y no el máximo. El uso de técnicas de *pooling* se sustenta también en la disminución del número de características en la red.\n",
    "\n",
    "<center><img src=\"./img/pooling.png\"></center>\n",
    "\n",
    "### **7.5.2 Calculo del número de características**\n",
    "\n",
    "Para calcular el tamaño de los mapas de características y el número total de característica de la red se usa la siguiente ecuación.\n",
    "\n",
    "$$\\large{ \\frac{W - F + 2P}{S} + 1 }$$\n",
    "\n",
    "Donde $W$ es el tamaño del ancho del mapa de características, $F$ el tamaño del kernel, $P$ el valor de padding y $S$ el valor del stride. De esta forma y utilizando la ecuación anterior en cada capa se puede controlar el tamaño de características en cada capa.\n",
    "\n",
    "_(Imágenes tomadas de: Dive into Deep Learning - Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola)_\n",
    "\n",
    "### **7.5.3 Dropout**\n",
    "\n",
    "Durante el entrenamiento es posible convertir algunos pesos en nulos, de modo que la red no aprenda las mismas conexiones en cada entrenamiento, si no que trate de encontrar diferentes caminos dentro de la red y así garantizar un aprendizaje más general.\n",
    "\n",
    "Esta es una técnica de regularización que previene la adaptación de las neuronas.\n",
    "\n",
    "\n",
    "<center><img src=\"./img/dropout.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlJ1RfzxU7xd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos la CNN\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "  # ( (28-5+2*2)/1 ) + 1 = 28   -> 28*28*16\n",
    "\n",
    "  torch.nn.ReLU(),\n",
    "\n",
    "  torch.nn.MaxPool2d(kernel_size=2),\n",
    "  # 28/2 = 14                 -> 14*14*16\n",
    "\n",
    "  torch.nn.Dropout(p=0.2),\n",
    "\n",
    "  torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "  # ( (14-5+2*2)/1 ) + 1 = 14   -> 14*14*32\n",
    "\n",
    "  torch.nn.ReLU(),\n",
    "\n",
    "  torch.nn.MaxPool2d(kernel_size=2),\n",
    "  # 14/2 = 7                 -> 7*7*32\n",
    "\n",
    "  torch.nn.Dropout(p=0.2),\n",
    "\n",
    "  torch.nn.Flatten(),\n",
    "  torch.nn.Linear(7*7*32, 10)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CHSt1F0VERj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos los criterios de evaluación y el optmizador\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPz2oFI2VG8q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Visualizamos la estructura de nuestra CNN\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsOwwxlfVIBW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Entrenamos la CNN\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "history = hl.History()\n",
    "canvas = hl.Canvas()\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  for batch_id, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n",
    "    model.train()\n",
    "    #print(X_train_batch.size())\n",
    "    Xtr = X_train_batch.unsqueeze(1)\n",
    "    #print(Xtr.size())\n",
    "    Y_pred = model(Xtr)\n",
    "\n",
    "    loss = criterion(Y_pred,Y_train_batch)\n",
    "\n",
    "    Y_pred = torch.argmax(Y_pred, 1)\n",
    "    f1 = f1_score(Y_train_batch, Y_pred, average='macro')\n",
    "\n",
    "    acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "    if iter%10 == 0:\n",
    "        #-- Visualizamos la evolución de los score loss y accuracy\n",
    "        history.log((epoch+1, iter), loss=loss, accuracy=acc)\n",
    "        with canvas:\n",
    "          canvas.draw_plot(history[\"loss\"])\n",
    "          canvas.draw_plot(history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX24Z53AVJ2O"
   },
   "source": [
    "### **7.5.4 Visualizando algunos mapas de características**\n",
    "\n",
    "La visualización del mapa de características es la representación gráfica de las activaciones de las diferentes características (o mapas de características) aprendidas por una red neuronal convolucional (CNN) u otro modelo de aprendizaje profundo. Estos mapas de características son el resultado de aplicar filtros convolucionales a la entrada de la red a medida que se propaga a través de las capas.\n",
    "\n",
    "Cuando se trabaja con imágenes, las primeras capas de una CNN suelen aprender características simples, como bordes, colores y texturas, mientras que las capas más profundas pueden aprender características más complejas y abstractas asociadas con objetos específicos.\n",
    "\n",
    "La visualización del mapa de características es útil para entender qué partes de la entrada son destacadas por diferentes filtros y capas de la red. Puede proporcionar información sobre lo que el modelo está mirando y detectando en una imagen.\n",
    "\n",
    "Existen varias técnicas para visualizar mapas de características, como la activación de mapas de calor que resalta las regiones más activas, la visualización de filtros que muestra los patrones aprendidos por los filtros, y la superposición de activaciones en la imagen original para comprender qué partes específicas de la entrada activaron ciertas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzO1hr0MVKrM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Visualizando los mapas de características de la primera capa convolucional\n",
    "kernels = list(model.children())[0].weight.detach()\n",
    "\n",
    "fig = pl.figure(figsize=(16,4))\n",
    "k = 0\n",
    "for i in range(kernels.size(0)):\n",
    "    pl.subplot(2,8,k+1)\n",
    "    pl.imshow(kernels[i].squeeze())\n",
    "    k += 1\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vtr6VHtWVMRq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Evaluamos el modelo con nuestro set de validación\n",
    "\n",
    "model.eval()\n",
    "Xvl = X_valid.unsqueeze(1)\n",
    "Y_pred = model(Xvl)\n",
    "loss = criterion(Y_pred,Y_valid)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_valid, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "\n",
    "print( 'Loss:{:.2f}, F1:{:.2f}, Acc:{:.2f}'.format(loss.item(), f1, acc ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.5 Uso de una GPU\n",
    "\n",
    "\n",
    "Una GPU, o Unidad de Procesamiento Gráfico (por sus siglas en inglés, Graphics Processing Unit), es un tipo de procesador diseñado específicamente para acelerar el procesamiento de gráficos y operaciones matemáticas intensivas. Aunque las GPUs tienen su origen en el procesamiento gráfico para juegos y aplicaciones multimedia, su capacidad para realizar cálculos paralelos de manera eficiente las ha convertido en una herramienta esencial para el desarrollo de modelos de Deep Learning (DL).\n",
    "\n",
    "La importancia de las GPUs en el desarrollo de modelos de DL se debe a varias razones:\n",
    "\n",
    "1. **Paralelismo Masivo:** Las GPUs están diseñadas para manejar múltiples tareas simultáneamente. Dado que muchas operaciones en modelos de DL, como multiplicaciones de matrices, pueden realizarse de manera independiente, las GPUs son altamente eficientes en realizar cálculos en paralelo.\n",
    "\n",
    "2. **Aceleración de Entrenamiento:** El entrenamiento de modelos de DL implica ajustar millones o incluso miles de millones de parámetros. Las GPUs permiten acelerar significativamente este proceso al realizar cálculos de manera paralela, lo que reduce el tiempo de entrenamiento de días a horas o incluso minutos.\n",
    "\n",
    "3. **Arquitecturas Especializadas:** Empresas como NVIDIA han desarrollado arquitecturas de GPU específicas para cargas de trabajo de aprendizaje profundo, como la arquitectura NVIDIA CUDA. Estas arquitecturas incluyen características y optimizaciones específicas para mejorar el rendimiento en tareas de DL.\n",
    "\n",
    "4. **Flexibilidad de Frameworks de DL:** Los frameworks populares de DL, como TensorFlow y PyTorch, están diseñados para aprovechar la capacidad de procesamiento paralelo de las GPUs. Esto facilita a los desarrolladores implementar y entrenar modelos de manera eficiente.\n",
    "\n",
    "5. **Desarrollo de Modelos más Complejos:** El uso de GPUs permite a los investigadores y desarrolladores abordar problemas más complejos mediante la creación de modelos más grandes y sofisticados. Esto ha llevado al desarrollo de modelos de DL más avanzados, como las redes neuronales profundas y los modelos de transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WMzxGYpVPDm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Después de activar el entorno GPU se selecciona el dispositivo\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9YJpLefVYhA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Definimos el modelo\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "  #out: ( (28-5+2*2)/1 ) + 1 = 28   -> 28 x 28 x16\n",
    "\n",
    "  torch.nn.ReLU(),\n",
    "\n",
    "  torch.nn.MaxPool2d(kernel_size=2),\n",
    "  #out: 28/2 = 14                 -> 14 x 14 x 16\n",
    "\n",
    "  torch.nn.Dropout(p=0.2),\n",
    "\n",
    "  torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "  #out: ( (14-5+2*2)/1 ) + 1 = 14   -> 14 x 14 x 32\n",
    "\n",
    "  torch.nn.ReLU(),\n",
    "\n",
    "  torch.nn.MaxPool2d(kernel_size=2),\n",
    "  #out: 14/2 = 7                 -> 7 x 7 x 32\n",
    "\n",
    "  torch.nn.Dropout(p=0.2),\n",
    "\n",
    "  torch.nn.Flatten(),\n",
    "  torch.nn.Linear(7*7*32, 10)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbdVsUczVgR9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#-- Cargamos el modelo en la GPU\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.1)\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "history2 = hl.History()\n",
    "canvas2 = hl.Canvas()\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for batch_id, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n",
    "\n",
    "        #-- Cargamos los datos en la GPU\n",
    "        X_train_batch, Y_train_batch = X_train_batch.to(device), Y_train_batch.to(device)\n",
    "\n",
    "        model.train()\n",
    "        Xtr = X_train_batch.unsqueeze(1)\n",
    "        Y_pred = model(Xtr)\n",
    "\n",
    "        loss = criterion(Y_pred,Y_train_batch)\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "\n",
    "        #-- Calculamos el f1 en la cpu\n",
    "        f1 = f1_score(Y_train_batch.cpu(),Y_pred.cpu(), average='macro')\n",
    "\n",
    "        acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter%10 == 0:\n",
    "            history2.log((epoch+1, iter), loss=loss, accuracy=acc)\n",
    "            with canvas2:\n",
    "                canvas2.draw_plot(history2[\"loss\"])\n",
    "                canvas2.draw_plot(history2[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63jFNGfbViw9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Validamos el modelo\n",
    "\n",
    "X_valid, Y_valid = X_valid.to(device), Y_valid.to(device)\n",
    "model.eval()\n",
    "Xvl = X_valid.unsqueeze(1)\n",
    "Y_pred = model(Xvl)\n",
    "loss = criterion(Y_pred,Y_valid)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_valid.cpu(), Y_pred.cpu(), average='macro')\n",
    "\n",
    "acc = sum(Y_valid == Y_pred)/len(Y_pred)\n",
    "\n",
    "print( 'Loss:{:.2f}, F1:{:.2f}, Acc:{:.2f}'.format(loss.item(), f1, acc ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9m9Rd6QOVoPW"
   },
   "source": [
    "### 7.5.6 Arquitecturas de CNN\n",
    "\n",
    "Existe una variedad de arquitecturas de CNN que han sido diseñadas utilizando diferentes combinaciones de capas y algoritmos para la obtención de mejores resultados.\n",
    "La mayoría de estas CNN han probado su habilidad en datasets como COCO, Imagenet y CIFAR100, obteniendo muy buenos resultados.\n",
    "A continuación se mencinaran algunas de las CNN más conocidas.\n",
    "\n",
    "\n",
    "**LeNet y AlexNet**\n",
    "\n",
    "A la izquierda la estructura de LeNet (La primera CNN) y AlexNet su predecesora. AlexNet fue diseñada para abordar el reto del dataset **Imagenet**.\n",
    "AlexNet, desarrollada por Alex Krizhevsky, Ilya Sutskever y Geoffrey Hinton en 2012, fue una red neuronal convolucional (CNN) que marcó un hito en la visión por computadora y el aprendizaje profundo. Destacó por su arquitectura profunda con ocho capas de aprendizaje, incluyendo capas convolucionales y totalmente conectadas. Introdujo el uso extensivo de Rectified Linear Units (ReLU) como funciones de activación, abordando la desaparición del gradiente. AlexNet implementó \"dropout\" para prevenir sobreajuste, aplicó aumento de datos y se benefició significativamente de la computación en paralelo con GPU. En la competición ImageNet, superó métodos tradicionales, influyendo en el desarrollo de redes neuronales profundas y popularizando el uso de CNN en visión por computadora.\n",
    "\n",
    "<center><img src=\"./img/alexnet.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpnGczFsVlrn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_KDeED0VuNF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(model.children())[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHJS0AtwVxN1"
   },
   "source": [
    "**De AlexNet a VGG**\n",
    "\n",
    "VGG (Visual Geometry Group) fue un grupo de investigación en la Universidad de Oxford que presentó VGGNet en 2014, una red neuronal convolucional (CNN) que se destacó por su estructura uniforme y profundidad. Utilizando bloques repetitivos de convoluciones 3x3 y agrupación máxima 2x2, VGGNet ofreció una arquitectura fácilmente escalable. Aunque no fue la primera en adoptar una arquitectura profunda, su simplicidad y comprensibilidad la hicieron influyente en el campo del aprendizaje profundo. Existieron variantes de 16 y 19 capas, contribuyendo al desarrollo de arquitecturas más avanzadas en la clasificación de imágenes.\n",
    "\n",
    "<center><img src=\"./img/vgg.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mka60F4YVz03",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F66F-9nQV1r8"
   },
   "source": [
    "**De VGG a NiN (Network in Network)**\n",
    "\n",
    "Network in Network (NiN) fue una arquitectura de red neuronal propuesta por los investigadores Min Lin, Qiang Chen y Shuicheng Yan en 2014. La característica distintiva de NiN radica en la introducción de bloques de \"micro-redes\" dentro de las capas convolucionales tradicionales. Estos bloques, denominados \"módulos NiN\", consisten en capas convolucionales 1x1 seguidas de capas convolucionales convencionales. Esta estructura permitió la captura de patrones más complejos y la mejora de la representación de características. Además, NiN promovió la utilización de capas convolucionales 1x1 como \"máquinas de aprendizaje profundo\" dentro de la red, ayudando a mejorar la eficiencia y reducir la dimensionalidad. Si bien NiN no reemplazó por completo las arquitecturas convencionales, su enfoque innovador influyó en la exploración de técnicas para mejorar la capacidad de representación de las redes neuronales convolucionales.\n",
    "\n",
    "<center><img src=\"./img/nin.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wt9PVr8mV3sL"
   },
   "source": [
    "**Redes Residuales - ResNet**\n",
    "\n",
    "ResNet, o Redes Residuales, fue una arquitectura de red neuronal propuesta por Kaiming He, Xiangyu Zhang, Shaoqing Ren y Jian Sun en 2015. Destacó por introducir el concepto de bloques residuales, donde las activaciones se combinan directamente con las activaciones anteriores, facilitando el entrenamiento de redes extremadamente profundas. La idea clave era permitir que las capas aprendieran las diferencias residuales en lugar de intentar aprender las funciones completas, lo que abordó el desafío de los gradientes que disminuyen en el entrenamiento de redes profundas. ResNet logró superar problemas de degradación y permitió entrenar redes con más de cien capas, llevando a un rendimiento excepcional en tareas de visión por computadora. Esta innovadora arquitectura se convirtió en un pilar fundamental en el diseño de redes neuronales profundas.\n",
    "\n",
    "<center><img src=\"./img/resnet-block.png\"></center>\n",
    "\n",
    "<center><img src=\"./img/resnet18-90.png\"></center>\n",
    "\n",
    "\n",
    "_(Imágenes tomadas de: Dive into Deep Learning - Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.5.7 Batch Normalization**\n",
    "\n",
    "Batch normalization es un método que normaliza cada sub-set de datos (bath_size), como se mencionó inicialmente es necesario que los datos se normalicen para evitar que se tengan distancias muy diferentes entre ellos. En una imagen a color se pueden tener valores de 0 hasta 255. Normalizando los datos las distancias de los datos van de 0 a 1. Esto ayuda a la red neuronal a trabajar mejor. Cuando normalizamos los datos solo la capa de entrada se beneficia de esto, conforme los datos pasan por otras capas ocultas esta normalización se va perdiendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFJxw7jvV5DN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwYKCwtFWBb1"
   },
   "source": [
    "## **7.6 Transferencia de Aprendizaje**\n",
    "\n",
    "Una de las ventajas del DL es el uso de modelos preentrenados para resolver tareas nuevas, tareas para las cuales la ANN no fue entrenada inicialmente.\n",
    "Esto es posible dado que en cada capa de la ANN se aprenden diferentes características con diferentes niveles de abstracción. La ANN se puede cortar en cualquier capa y utilizar los pesos aprendidos hasta esa capa. A la capa cortada se le pueden anexar nuevas capas. Posteriormente se entrena el modelo con los nuevos datos. Este entrenamiento es más rápido pues inicia desde un punto avanzado y no desde cero. Esta técnica se conoce como transferencia de aprendizaje (**transfer learning**).\n",
    "\n",
    "<center><img src=\"./img/transfer.png\"></center>\n",
    "Sebastian Ruder, \"Transfer Learning - Machine Learning's Next Frontier\". http://ruder.io/transfer-learning/, 2017.\n",
    "\n",
    "<br>\n",
    "\n",
    "El *Transfer Learning* es un método de optimización, un atajo para ahorrar tiempo y obtener mejores resultados, pues se suelen utilizar modelos entrenados con grandes datasets, que continen alta cantidad de clases y variabilidad de datos.\n",
    "\n",
    "<br>\n",
    "\n",
    "Este método tiene tres grandes ventajas:\n",
    "\n",
    "* **Inicio avanzado**. La capacidad inicial en el modelo de origen (antes de refinar el modelo) es mayor de lo que sería iniciando desde cero.\n",
    "* **Pendiente más alta**. La tasa de precisión durante el entrenamiento del modelo es más pronunciada.\n",
    "* **Asíntota superior**. La tasa de convergencia del modelo entrenado es mejor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np3mtCnEWD0s"
   },
   "source": [
    "### **7.6.1 Cargando un modelo pre-entrenado**\n",
    "\n",
    "Para nuestro ejercicio usaremos ResNet18, una red Red Neuronal Convolucional con 18 capas de profundidad. Recordemos que el nombre de **Residual-Net** proviene de la estrategia de usar conexiones de salto residualmente dentro de bloques (llamados bloques residuales, ver Figura), donde la entrada *x* se agrega directamente a la salida del bloque, es decir, *F(x) + x* garantizando el aumento en la profundidad de la red al omitir ciertas capas utilizando conexiones de omisión o bloques residuales. Un gran avance para el problema de optimización/degradación con redes profundas.\n",
    "[Paper de presentación de ResNet](https://arxiv.org/pdf/1512.03385.pdf).\n",
    "\n",
    "<center><img src=\"./img/resnet.png\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "El modelo pre-entrenado puede clasificar imágenes en al menos 1000 categorías diferentes, tal como teclado, mouse, lápiz y diferentes clases de animales. Dada la variedad de objetos en el dataset de entrenamieto el modelo es rico en representación de features en un alto rango de clases. ResNet fue entrenado con [Imagenet](https://image-net.org/) un gigantesco dataset visual diseñado para el uso de proyectos en reconocimiento de objetos. Imagenet tiene al menos 14 millones de imágenes anotadas. La entrada de la red tiene un tamaño de 224x224x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC8_xlEqWGpO"
   },
   "source": [
    "Al momento de cargar los datos es necesario reescalarlos al tamaño de entrada del modelo reciclado en este caso (224,224,3). Es necesario reescalar y normalizar las imágenes (La normalización se hace usando la media y la desviación estándar). La normalización ayuda a la red a converger más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6V27ZLhHWIbH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "#--- Transformamos los datos para adaptarlos a la entrada de ResNet 224x224 px\n",
    "data_transform = transforms.Compose([\n",
    "                 transforms.Resize((224, 224)),\n",
    "                 transforms.Grayscale(3), #Dado que MNIST tiene un solo canal, lo cambiamos a 3 para no tener que modificar más capas en el modelo\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xII7WRKWLAb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cargamos los datos de entrenamiento en listas\n",
    "from PIL import Image\n",
    "\n",
    "N_train = len(train_files)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i, train_file in enumerate(train_files):\n",
    "    Y_train.append( int(train_file.split('/')[3]) )\n",
    "    X_train.append( np.array(data_transform(Image.open(train_file) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usyW0DRkWMIt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cargamos los datos de testeo en listas\n",
    "N_test = len(test_files)\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for i, test_file in enumerate(test_files):\n",
    "    Y_test.append( int(test_file.split('/')[3]) )\n",
    "    X_test.append( np.array(data_transform(Image.open(test_file)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ccDQnV6WMBv"
   },
   "outputs": [],
   "source": [
    "#-- Visualizamos los datos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(X_test[i*15].reshape(224,224,3))\n",
    "    plt.title(Y_test[i*15])\n",
    "    plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJBen8hBWO3V"
   },
   "outputs": [],
   "source": [
    "#--- Convetimos las listas con los datos a tensores de torch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X_train = Variable(torch.from_numpy(np.array(X_train))).float()\n",
    "Y_train = Variable(torch.from_numpy(np.array(Y_train))).long()\n",
    "\n",
    "X_test = Variable(torch.from_numpy(np.array(X_test))).float()\n",
    "Y_test = Variable(torch.from_numpy(np.array(Y_test))).long()\n",
    "\n",
    "X_train.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CptnkefVWP2d"
   },
   "outputs": [],
   "source": [
    "#-- Creamos el DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7N58WyTmWRUV"
   },
   "source": [
    "### **7.6.2 Entrenando el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aH0o75qWWS3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Seleccionamos y cargamos el modelo\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZJPYYQnWUJh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Congelamos los pesos en las capas del modelo para que no se actualicen\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "#--- Definimos el número de clases\n",
    "out_dim = 10\n",
    "\n",
    "#--- Reescribimos la nueva capa de salida con el nuevo dataset\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.fc.in_features, out_dim)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model.state_dict())\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTxyf075WXEJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Visualizamos la estructura de nuestra CNN\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKu1I8BlWYeA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Creamos variables para almacenar los scores en cada época\n",
    "\n",
    "#model = model.cuda()\n",
    "\n",
    "model.train()\n",
    "\n",
    "#--- Definimos nuestro criterio de evaluación y el optimizador\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#--- Entrenamos el modelo usando únicamente 5 épocas\n",
    "n_epochs = 5\n",
    "\n",
    "history = hl.History()\n",
    "canvas = hl.Canvas()\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, (X_train_batch, Y_train_batch) in enumerate(train_dl):\n",
    "        # Pasamos os datos a 'cuda'\n",
    "\n",
    "        # X_train_batch = X_train_batch.cuda()\n",
    "        # Y_train_batch = Y_train_batch.cuda()\n",
    "\n",
    "        # Realiza una predicción\n",
    "        Y_pred = model(X_train_batch)\n",
    "\n",
    "        # Calcula el loss\n",
    "        loss = criterion(Y_pred, Y_train_batch)\n",
    "\n",
    "        Y_pred = torch.argmax(Y_pred, 1)\n",
    "\n",
    "        # Calcula el accuracy\n",
    "        acc = sum(Y_train_batch == Y_pred)/len(Y_pred)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter%10 == 0:\n",
    "            #-- Visualizamos la evolución de los score loss y accuracy\n",
    "            history.log((epoch+1, iter), loss=loss, accuracy=acc)\n",
    "            with canvas:\n",
    "                canvas.draw_plot(history[\"loss\"])\n",
    "                canvas.draw_plot(history[\"accuracy\"])\n",
    "\n",
    "        iter += 1\n",
    "        del X_train_batch, Y_train_batch, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nxT548BWYYo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Validamos el modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# model.cpu()\n",
    "model.eval()\n",
    "\n",
    "Y_pred = model(X_test)\n",
    "loss = criterion(Y_pred,Y_test)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, 1)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "acc = sum(Y_test == Y_pred)/len(Y_pred)\n",
    "\n",
    "print( 'Loss:{:.2f}, F1:{:.2f}, Acc:{:.2f}'.format(loss.item(), f1, acc ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_HVm0tXWbH6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Guardamos el nuevo Modelo\n",
    "torch.save(model,open('./ResNet_MNIST.pt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7evhuMFQWeEX"
   },
   "outputs": [],
   "source": [
    "CM(Y_test, Y_pred, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.7 Lecturas Recomendadas**\n",
    "\n",
    "1. [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)\n",
    "\n",
    "2. [Dive into Deep Learning](https://d2l.ai/index.html)\n",
    "\n",
    "3. [Attention is all you need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPHsOUuB7HVCYTVPxYcT7/Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
